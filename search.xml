<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Linux常用命令集合</title>
    <url>/2024/06/27/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<h3 id="Linux命令">Linux命令</h3>
<p>Linux 是一个功能强大的操作系统，它提供了大量的命令来执行各种任务。以下是一些常用的 Linux 命令及其简要说明</p>
<h4 id="vim编辑器：">vim编辑器：</h4>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim a.java   	进入一般模式</span><br><span class="line">i(按键)   		进入插入模式(编辑模式)</span><br><span class="line">ESC(按键)  		退出</span><br><span class="line">:wq 			保存退出（shift+：调起输入框）</span><br><span class="line">:q！			不保存退出（shift+：调起输入框）（内容有更改）(强制退出，不保留更改内容)</span><br><span class="line">:q				不保存退出（shift+：调起输入框）（没有内容更改）</span><br></pre></td></tr></table></figure>
<h4 id="文件和目录操作：">文件和目录操作：</h4>
<h5 id="ls-列出目录内容"><code>ls</code>: 列出目录内容</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ll				查看当前目录下内容（LL的小写）</span><br></pre></td></tr></table></figure>
<h5 id="cd-更改目录"><code>cd</code>: 更改目录</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~			当前用户目录</span><br><span class="line"><span class="built_in">cd</span> /			根目录</span><br><span class="line"><span class="built_in">cd</span> -			上一次访问的目录</span><br><span class="line"><span class="built_in">cd</span> ..			上一级目录</span><br></pre></td></tr></table></figure>
<h5 id="pwd-显示当前目录路径"><code>pwd</code>: 显示当前目录路径</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">pwd</span>				查看当前工作目录</span><br></pre></td></tr></table></figure>
<h5 id="mkdir-创建目录"><code>mkdir</code>: 创建目录</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> aaa		在当前目录下创建aaa目录，相对路径；</span><br><span class="line"><span class="built_in">mkdir</span> ./bbb		在当前目录下创建bbb目录，相对路径；</span><br><span class="line"><span class="built_in">mkdir</span> /ccc		在根目录下创建ccc目录，绝对路径；</span><br><span class="line"><span class="built_in">mkdir</span> -p temp/nginx    创建递归目录，创建里面没有的目录文件</span><br></pre></td></tr></table></figure>
<h5 id="rmdir-删除空目录"><code>rmdir</code>: 删除空目录</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="rm-删除文件或目录（需谨慎使用）"><code>rm</code>: 删除文件或目录（需谨慎使用）</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /bbb			强制删除/目录下的bbb目录。如果bbb目录中还有子目录，也会被强制删除，不会提示；</span><br><span class="line"><span class="built_in">rm</span> -r /bbb			普通删除。会询问你是否删除每一个文件</span><br><span class="line"><span class="built_in">rmdir</span> test01		目录的删除</span><br></pre></td></tr></table></figure>
<h5 id="cp-复制文件或目录"><code>cp</code>: 复制文件或目录</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r /aaa /bbb			将/目录下的aaa目录复制到/bbb目录下，在/bbb目录下的名称为aaa</span><br><span class="line"><span class="built_in">cp</span> -r /aa /bbb/aaa		将/目录下的aa目录复制到/bbb目录下，且修改名为aaa;</span><br></pre></td></tr></table></figure>
<h5 id="mv-移动或重命名文件或目录"><code>mv</code>: 移动或重命名文件或目录</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> 原先目录 文件的名称   <span class="built_in">mv</span> tomcat001 tomcat    重命名</span><br><span class="line"><span class="built_in">mv</span>	/aaa /bbb		    将根目录下的aaa目录，移动到bbb目录下(假如没有bbb目录，则重命名为bbb)；</span><br><span class="line"><span class="built_in">mv</span>	bbbb usr/bbb		将当前目录下的bbbb目录，移动到usr目录下，并且修改名称为bbb；</span><br><span class="line"><span class="built_in">mv</span>	bbb usr/aaa			将当前目录下的bbbb目录，移动到usr目录下，并且修改名称为aaa；</span><br></pre></td></tr></table></figure>
<h5 id="touch-创建空文件或更新文件时间戳"><code>touch</code>: 创建空文件或更新文件时间戳</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">touch</span> testFile    创建文件</span><br></pre></td></tr></table></figure>
<h5 id="ln-创建链接文件（硬链接或符号链接）"><code>ln</code>: 创建链接文件（硬链接或符号链接）</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /usr/local/app /data  创建软连接时，data目录后不加 / (加上后是查找其下一级目录)</span><br></pre></td></tr></table></figure>
<h5 id="find-在文件系统中查找文件"><code>find</code>: 在文件系统中查找文件</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="文本操作">文本操作</h4>
<h5 id="cat-显示文件内容"><code>cat</code>: 显示文件内容</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> a.java		查看a.java文件的最后一页内容；</span><br></pre></td></tr></table></figure>
<h5 id="more-分页显示文件内容"><code>more</code>: 分页显示文件内容</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">more a.java		从第一页开始查看a.java文件内容，按回车键一行一行进行查看，</span><br><span class="line">                    按空格键一页一页进行查看，q退出；</span><br></pre></td></tr></table></figure>
<h5 id="less-与-more-类似，但功能更强大"><code>less</code>: 与 <code>more</code> 类似，但功能更强大</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">less a.java		从第一页开始查看a.java文件内容，按回车键一行一行的看，</span><br><span class="line">                按空格键一页一页的看，支持使用PageDown和PageUp翻页，q退出；</span><br></pre></td></tr></table></figure>
<h5 id="head-显示文件开头内容"><code>head</code>: 显示文件开头内容</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">head</span> a.java				查看a.java文件的前10行内容；</span><br><span class="line"><span class="built_in">head</span> -n 7 a.java		查看a.java文件的前7行内容；</span><br></pre></td></tr></table></figure>
<h5 id="tail-显示文件末尾内容"><code>tail</code>: 显示文件末尾内容</h5>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">tail -<span class="keyword">f</span> <span class="keyword">a</span>.java			查看<span class="keyword">a</span>.java文件的后<span class="number">10</span>行内容；</span><br><span class="line">tail -n <span class="number">7</span> <span class="keyword">a</span>.java		查看<span class="keyword">a</span>.java文件的后<span class="number">7</span>行内容；</span><br></pre></td></tr></table></figure>
<h5 id="grep-在文件中搜索匹配的行"><code>grep</code>: 在文件中搜索匹配的行</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep under 123.txt			在123.txt文件中搜索under字符串，大小写敏感，显示行；</span><br><span class="line">grep -n under 123.txt		在123.txt文件中搜索under字符串，大小写敏感，显示行及行号；</span><br><span class="line">grep -v under 123.txt		在123.txt文件中搜索under字符串，大小写敏感，显示没搜索到的行；</span><br><span class="line">grep -i under 123.txt		在123.txt文件中搜索under字符串，大小写敏感，显示行；</span><br><span class="line">grep -ni under 123.txt		在123.txt文件中搜索under字符串，大小写敏感，显示行及行号；</span><br></pre></td></tr></table></figure>
<h5 id="sed-流编辑器，用于对输入流（文件或管道）进行基本文本转换"><code>sed</code>: 流编辑器，用于对输入流（文件或管道）进行基本文本转换</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/Jack/me/g/ replace.java    全文将Jack替换为me(g是全部替换,不加只替换首个)</span></span><br></pre></td></tr></table></figure>
<h5 id="awk-用于文本和数据提取的工具"><code>awk</code>: 用于文本和数据提取的工具</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk [options] <span class="string">&#x27;cmd&#x27;</span> file</span><br></pre></td></tr></table></figure>
<h4 id="权限和用户管理：">权限和用户管理：</h4>
<h5 id="chmod-更改文件或目录的权限"><code>chmod</code>: 更改文件或目录的权限</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="chown-更改文件或目录的所有者和组"><code>chown</code>: 更改文件或目录的所有者和组</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"><span class="comment">##### `chgrp`: 更改文件或目录的组</span></span><br><span class="line"></span><br><span class="line">```bash</span><br></pre></td></tr></table></figure>
<h5 id="useradd-添加新用户"><code>useradd</code>: 添加新用户</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd –d /usr/sum -m <span class="built_in">sum</span></span><br></pre></td></tr></table></figure>
<h5 id="userdel-删除用户"><code>userdel</code>: 删除用户</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"><span class="comment">##### `groupadd`: 添加新组</span></span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">groupadd groupname</span><br></pre></td></tr></table></figure>
<h5 id="groupdel-删除组"><code>groupdel</code>: 删除组</h5>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">groupdel groupname</span><br></pre></td></tr></table></figure>
<h5 id="id-显示当前用户或指定用户的实际和有效用户ID和组ID"><code>id</code>: 显示当前用户或指定用户的实际和有效用户ID和组ID</h5>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">```</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#### `su`: 切换到另一个用户账户</span></span></span><br><span class="line"></span><br><span class="line">```bash</span><br></pre></td></tr></table></figure>
<h5 id="sudo-以另一个用户的身份执行命令（通常用于超级用户）"><code>sudo</code>: 以另一个用户的身份执行命令（通常用于超级用户）</h5>
<h4 id="进程管理：">进程管理：</h4>
<h5 id="ps-显示当前进程的快照。"><code>ps</code>: 显示当前进程的快照。</h5>
<h5 id="top-动态显示进程信息（实时）。"><code>top</code>: 动态显示进程信息（实时）。</h5>
<h5 id="htop-一个增强的-top-命令，具有更多的功能和更好的界面。"><code>htop</code>: 一个增强的 top 命令，具有更多的功能和更好的界面。</h5>
<h5 id="kill-发送信号以终止、继续或停止进程。"><code>kill</code>: 发送信号以终止、继续或停止进程。</h5>
<h5 id="pkill-和-killall-根据名称发送信号给进程。"><code>pkill</code> 和 <code>killall</code>: 根据名称发送信号给进程。</h5>
<h5 id="nohup-运行命令，忽略挂起（HUP）信号。"><code>nohup</code>: 运行命令，忽略挂起（HUP）信号。</h5>
<h5 id="fg-和-bg-将作业放到前台或后台执行。"><code>fg</code> 和 <code>bg</code>: 将作业放到前台或后台执行。</h5>
<h5 id="jobs-列出当前-shell-会话中的作业。"><code>jobs</code>: 列出当前 shell 会话中的作业。</h5>
<h4 id="系统信息：">系统信息：</h4>
<h5 id="uname-显示系统信息（内核名称、主机名、内核版本号等）。"><code>uname</code>: 显示系统信息（内核名称、主机名、内核版本号等）。</h5>
<h5 id="uptime-显示系统运行时间、用户数、负载等。"><code>uptime</code>: 显示系统运行时间、用户数、负载等。</h5>
<h5 id="w-显示已登录的用户和他们正在执行的命令。"><code>w</code>: 显示已登录的用户和他们正在执行的命令。</h5>
<h5 id="who-显示已登录的用户。"><code>who</code>: 显示已登录的用户。</h5>
<h5 id="last-显示最近登录的用户列表。"><code>last</code>: 显示最近登录的用户列表。</h5>
<h5 id="dmidecode-显示硬件信息（需要-root-权限）。"><code>dmidecode</code>: 显示硬件信息（需要 root 权限）。</h5>
<h5 id="lscpu-和-lshw-显示-CPU-和硬件的详细信息。"><code>lscpu</code> 和 <code>lshw</code>: 显示 CPU 和硬件的详细信息。</h5>
<h5 id="free-显示内存使用情况。"><code>free</code>: 显示内存使用情况。</h5>
<h5 id="vmstat-报告关于进程、内存、分页、块-IO、陷阱和-CPU-活动的信息。"><code>vmstat</code>: 报告关于进程、内存、分页、块 IO、陷阱和 CPU 活动的信息。</h5>
<h4 id="网络管理：">网络管理：</h4>
<h5 id="ifconfig-或-ip-显示和配置网络接口。"><code>ifconfig</code> 或 <code>ip</code>: 显示和配置网络接口。</h5>
<h5 id="netstat-显示网络连接、路由表、接口统计等。"><code>netstat</code>: 显示网络连接、路由表、接口统计等。</h5>
<h5 id="ss-另一个用于查看系统套接字统计信息的工具（比-netstat-更快）。"><code>ss</code>: 另一个用于查看系统套接字统计信息的工具（比 netstat 更快）。</h5>
<h5 id="ping-发送-ICMP-ECHO-REQUEST-到网络主机。"><code>ping</code>: 发送 ICMP ECHO_REQUEST 到网络主机。</h5>
<h5 id="traceroute-或-tracert-显示数据包从源主机到目标主机之间的路由。"><code>traceroute</code> 或 <code>tracert</code>: 显示数据包从源主机到目标主机之间的路由。</h5>
<h5 id="nslookup-和-dig-查询-DNS-记录。"><code>nslookup</code> 和 <code>dig</code>: 查询 DNS 记录。</h5>
<h5 id="telnet-用于登录到远程主机的-TELNET-会话。"><code>telnet</code>: 用于登录到远程主机的 TELNET 会话。</h5>
<h5 id="nc-netcat-一个小巧但功能强大的网络工具，可以读写-TCP-和-UDP-数据。"><code>nc</code> (netcat): 一个小巧但功能强大的网络工具，可以读写 TCP 和 UDP 数据。</h5>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>c++关键字</title>
    <url>/2024/06/23/c-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h3 id="概述：">概述：</h3>
<p>C++ 是一种广泛使用的、通用的、面向对象的编程语言，它支持过程化编程、数据抽象、面向对象编程和泛型编程等多种编程范式。C++ 是在 C 语言的基础上发展起来的，它增加了许多新的特性，如类、继承、多态、模板、异常处理、命名空间等。</p>
<p>以下是 C++ 的一些基本特点：</p>
<table>
<thead>
<tr>
<th style="text-align:left">特点</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">面向对象</td>
<td style="text-align:left">C++ 支持面向对象编程（OOP），通过类（class）和对象（object）的概念。</td>
</tr>
<tr>
<td style="text-align:left">继承</td>
<td style="text-align:left">一个类可以从另一个类继承，从而重用代码并扩展功能。</td>
</tr>
<tr>
<td style="text-align:left">多态</td>
<td style="text-align:left">通过虚函数（virtual functions）和继承，C++ 支持运行时多态，允许不同的对象对同一消息做出不同的响应。</td>
</tr>
<tr>
<td style="text-align:left">模板</td>
<td style="text-align:left">C++ 提供了模板（templates），允许程序员编写适用于多种数据类型的通用代码。</td>
</tr>
<tr>
<td style="text-align:left">异常处理</td>
<td style="text-align:left">C++ 引入了异常处理机制，用于处理程序运行时的错误情况。</td>
</tr>
<tr>
<td style="text-align:left">命名空间</td>
<td style="text-align:left">C++ 支持命名空间（namespaces），用于避免名称冲突和组织代码。</td>
</tr>
<tr>
<td style="text-align:left">标准库</td>
<td style="text-align:left">C++ 标准库提供了大量的函数和类，用于处理常见的编程任务，如字符串处理、文件操作、内存管理等。</td>
</tr>
<tr>
<td style="text-align:left">与C语言兼容</td>
<td style="text-align:left">C++ 是 C 语言的超集，这意味着任何有效的 C 程序也是有效的 C++ 程序（但可能不是最优的 C++ 程序）。</td>
</tr>
</tbody>
</table>
<p>以下是一个简单的 C++ 程序示例，用于输出 “Hello, World!”：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Hello, World!&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例中，<code>#include &lt;iostream&gt;</code> 指令告诉编译器包含标准输入输出流库。<code>int main()</code> 是程序的入口点。<code>std::cout</code> 是一个输出流对象，用于将文本发送到标准输出（通常是屏幕）。<code>&lt;&lt;</code> 是一个插入运算符，用于将数据插入到输出流中。<code>std::endl</code> 是一个操纵符，用于在输出中插入一个新行。最后，<code>return 0;</code> 表示程序正常退出。</p>
<h3 id="对C的扩充：">对C的扩充：</h3>
<p>下面是一个简化的表格，展示了C++在非面向对象方面对C语言的主要扩充点：</p>
<table>
<thead>
<tr>
<th style="text-align:left">扩充点</th>
<th>C++特性</th>
<th>C语言对应/比较</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">类型安全性</td>
<td>强类型检查</td>
<td>弱类型检查，依赖程序员注意</td>
</tr>
<tr>
<td style="text-align:left">输入输出流</td>
<td><code>iostream</code>库</td>
<td>标准I/O库（如<code>stdio.h</code>）</td>
</tr>
<tr>
<td style="text-align:left">内存管理</td>
<td><code>new</code>和<code>delete</code></td>
<td><code>malloc</code>和<code>free</code></td>
</tr>
<tr>
<td style="text-align:left">引用（Reference）</td>
<td>变量别名</td>
<td>指针操作</td>
</tr>
<tr>
<td style="text-align:left">函数重载</td>
<td>允许同名不同参数函数</td>
<td>不支持</td>
</tr>
<tr>
<td style="text-align:left">缺省参数</td>
<td>允许函数参数有默认值</td>
<td>不支持</td>
</tr>
<tr>
<td style="text-align:left">内联函数</td>
<td>提高函数调用效率</td>
<td>无直接对应</td>
</tr>
<tr>
<td style="text-align:left">命名空间</td>
<td>组织代码，避免命名冲突</td>
<td>全局作用域，可能导致冲突</td>
</tr>
<tr>
<td style="text-align:left">运算符重载</td>
<td>允许重载运算符</td>
<td>不支持</td>
</tr>
<tr>
<td style="text-align:left">条件编译</td>
<td><code>#ifdef</code>, <code>#ifndef</code>等</td>
<td><code>#if</code>, <code>#else</code>, <code>#endif</code></td>
</tr>
<tr>
<td style="text-align:left">宏定义</td>
<td><code>#define</code></td>
<td><code>#define</code></td>
</tr>
<tr>
<td style="text-align:left">预处理撤销</td>
<td><code>#undef</code></td>
<td>无直接对应</td>
</tr>
<tr>
<td style="text-align:left">模板（Templates）</td>
<td>泛型编程</td>
<td>无直接对应</td>
</tr>
<tr>
<td style="text-align:left">异常处理</td>
<td><code>try</code>, <code>catch</code>, <code>throw</code></td>
<td>无直接对应，使用错误码</td>
</tr>
</tbody>
</table>
<p>C++的关键字是编程语言中预先保留的标识符，用于定义语言的结构和语法。在C++中，这些关键字不能被用作变量名、函数名或其他标识符的名称。以下是C++（不包括C++11新增的关键字）中的一部分主要关键字，按照不同的功能分类进行简述：</p>
<h3 id="数据类型关键字">数据类型关键字:</h3>
<table>
<thead>
<tr>
<th>基本数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>bool</td>
<td>布尔类型，用于表示逻辑值（true或false）</td>
</tr>
<tr>
<td>char</td>
<td>字符类型，用于存储字符值</td>
</tr>
<tr>
<td>int</td>
<td>整型，用于存储整数</td>
</tr>
<tr>
<td>float、double、long double</td>
<td>浮点型，用于存储小数</td>
</tr>
<tr>
<td>signed、unsigned</td>
<td>用于指定整数类型是有符号还是无符号的</td>
</tr>
<tr>
<td>short、long</td>
<td>用于指定整数类型的长度</td>
</tr>
<tr>
<td>void</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>复合数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>class</td>
<td>用于定义类</td>
</tr>
<tr>
<td>struct</td>
<td>用于定义结构体</td>
</tr>
<tr>
<td>union</td>
<td>用于定义联合体</td>
</tr>
<tr>
<td>enum</td>
<td>用于定义枚举类型</td>
</tr>
</tbody>
</table>
<h3 id="控制语句关键字">控制语句关键字:</h3>
<table>
<thead>
<tr>
<th>循环语句</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>for</td>
<td>用于执行固定次数的循环</td>
</tr>
<tr>
<td>while</td>
<td>用于在条件为真时重复执行代码块</td>
</tr>
<tr>
<td>do…while</td>
<td>与<code>while</code>类似，但循环体至少会执行一次</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>条件语句</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>if</td>
<td>用于根据条件执行不同的代码块</td>
</tr>
<tr>
<td>else</td>
<td>与<code>if</code>一起使用，用于指定条件为假时执行的代码块</td>
</tr>
<tr>
<td>switch</td>
<td>用于根据表达式的值选择不同的代码块执行</td>
</tr>
<tr>
<td>case</td>
<td>与<code>switch</code>一起使用，用于指定表达式可能的值</td>
</tr>
<tr>
<td>default</td>
<td>与<code>switch</code>一起使用，用于指定表达式不匹配任何<code>case</code>时执行的代码块</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>跳转语句</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>break</td>
<td>用于跳出当前循环或<code>switch</code>语句</td>
</tr>
<tr>
<td>continue</td>
<td>用于跳过当前循环的剩余部分，直接进入下一次循环</td>
</tr>
<tr>
<td>goto</td>
<td>无条件跳转到指定的标签位置（在现代编程中很少使用）</td>
</tr>
<tr>
<td>return</td>
<td>用于从函数中返回值并结束函数执行</td>
</tr>
</tbody>
</table>
<h3 id="存储类型关键字">存储类型关键字:</h3>
<table>
<thead>
<tr>
<th>存储关键字</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>auto</td>
<td>尽管在C++11中有更多用途，但在C++98/03中主要用于自动存储期变量的声明</td>
</tr>
<tr>
<td>extern</td>
<td>用于声明在其他文件中定义的变量或函数</td>
</tr>
<tr>
<td>register</td>
<td>建议编译器将变量存储在寄存器中（但现代编译器通常忽略此建议）</td>
</tr>
<tr>
<td>static</td>
<td>用于声明静态变量或静态成员函数</td>
</tr>
</tbody>
</table>
<h3 id="其他关键字">其他关键字:</h3>
<table>
<thead>
<tr>
<th>另外的常用关键字</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sizeof</td>
<td>用于计算数据类型或变量的大小（以字节为单位）</td>
</tr>
<tr>
<td>typedef</td>
<td>用于为数据类型定义别名</td>
</tr>
<tr>
<td>volatile</td>
<td>用于修饰变量，表示该变量可能在程序外部被意外地改变（如多线程或硬件操作）</td>
</tr>
<tr>
<td>namespace</td>
<td>用于定义命名空间，以避免命名冲突</td>
</tr>
<tr>
<td>using</td>
<td>用于在当前作用域中引入命名空间中的名称</td>
</tr>
<tr>
<td>friend</td>
<td>用于声明友元函数或友元类，它们可以访问类的私有和保护成员</td>
</tr>
<tr>
<td>explicit</td>
<td>用于防止类构造函数被用于隐式类型转换</td>
</tr>
<tr>
<td>mutable</td>
<td>用于修饰类的非静态成员变量，即使在<code>const</code>成员函数中也可以修改它</td>
</tr>
</tbody>
</table>
<h3 id="c-11新引入：">c++11新引入：</h3>
<table>
<thead>
<tr>
<th>关键字</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>alignas</code></td>
<td>用于指定变量或类型的对齐要求</td>
</tr>
<tr>
<td><code>alignof</code></td>
<td>用于获取变量或类型的对齐要求</td>
</tr>
<tr>
<td><code>char16_t</code></td>
<td>16位字符类型</td>
</tr>
<tr>
<td><code>char32_t</code></td>
<td>32位字符类型</td>
</tr>
<tr>
<td><code>constexpr</code></td>
<td>声明编译时常量表达式</td>
</tr>
<tr>
<td><code>decltype</code></td>
<td>用于类型推导，返回表达式的类型</td>
</tr>
<tr>
<td><code>final</code></td>
<td>禁止类被继承，或禁止虚函数被重写</td>
</tr>
<tr>
<td><code>noexcept</code></td>
<td>指定函数不会抛出异常</td>
</tr>
<tr>
<td><code>nullptr</code></td>
<td>表示空指针常量</td>
</tr>
<tr>
<td><code>override</code></td>
<td>检查子类虚函数是否重写了某个基类虚函数</td>
</tr>
<tr>
<td><code>static_assert</code></td>
<td>在编译时进行断言</td>
</tr>
<tr>
<td><code>thread_local</code></td>
<td>声明变量的线程局部存储期</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>STL标准模板库</title>
    <url>/2024/06/26/STL%E6%A0%87%E5%87%86%E6%A8%A1%E6%9D%BF%E5%BA%93/</url>
    <content><![CDATA[<h3 id="概述：">概述：</h3>
<p>STL（Standard Template Library，标准模板库）是C++标准库的一部分，它提供了大量的模板类和函数，用于执行常见的算法和数据结构操作。STL的主要目的是提供一个统一、高效、可重用的数据结构和算法库，以减少程序员在编写这些基础代码时的重复工作。</p>
<h3 id="优点：">优点：</h3>
<ul>
<li>STL 是 C++的一部分，因此不用额外安装什么，它被内建在你的编译器之内。</li>
<li>程序员可以不用思考 STL 具体的实现过程，只要能够熟练使用 STL 就 OK 了。</li>
<li>STL 具有高可重用性，高性能，高移植性，跨平台的优点。</li>
</ul>
<h3 id="组成：">组成：</h3>
<ul>
<li>容器、迭代器、算法、函数对象、适配器和分配器</li>
</ul>
<table>
<thead>
<tr>
<th>类别</th>
<th>示例</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>容器（Containers）</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>序列容器</td>
<td><code>vector</code></td>
<td>动态数组，支持快速随机访问</td>
</tr>
<tr>
<td></td>
<td><code>deque</code></td>
<td>双端队列，支持在两端快速插入和删除</td>
</tr>
<tr>
<td></td>
<td><code>list</code></td>
<td>双向链表，支持在任何位置快速插入和删除</td>
</tr>
<tr>
<td>关联容器</td>
<td><code>set</code></td>
<td>有序集合，不允许重复元素</td>
</tr>
<tr>
<td></td>
<td><code>multiset</code></td>
<td>有序集合，允许重复元素</td>
</tr>
<tr>
<td></td>
<td><code>map</code></td>
<td>键值对集合，键唯一，值可重复</td>
</tr>
<tr>
<td></td>
<td><code>multimap</code></td>
<td>键值对集合，键可重复</td>
</tr>
<tr>
<td>容器适配器</td>
<td><code>stack</code></td>
<td>后进先出（LIFO）容器</td>
</tr>
<tr>
<td></td>
<td><code>queue</code></td>
<td>先进先出（FIFO）容器</td>
</tr>
<tr>
<td></td>
<td><code>priority_queue</code></td>
<td>优先级队列，元素根据优先级排序</td>
</tr>
<tr>
<td><strong>迭代器（Iterators）</strong></td>
<td></td>
<td>访问容器中元素的通用接口</td>
</tr>
<tr>
<td></td>
<td><code>begin()</code></td>
<td>返回指向容器第一个元素的迭代器</td>
</tr>
<tr>
<td></td>
<td><code>end()</code></td>
<td>返回指向容器尾后位置的迭代器（不指向任何元素）</td>
</tr>
<tr>
<td><strong>算法（Algorithms）</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td><code>sort()</code></td>
<td>对容器中的元素进行排序</td>
</tr>
<tr>
<td></td>
<td><code>find()</code></td>
<td>在容器中查找元素</td>
</tr>
<tr>
<td></td>
<td><code>copy()</code></td>
<td>复制容器中的元素</td>
</tr>
<tr>
<td></td>
<td>…</td>
<td>其他各种算法，如 <code>remove()</code>, <code>reverse()</code>, <code>binary_search()</code> 等</td>
</tr>
<tr>
<td><strong>函数对象（Function Objects）</strong></td>
<td></td>
<td>类似于函数，但可以作为对象传递和存储</td>
</tr>
<tr>
<td></td>
<td><code>less&lt;T&gt;</code></td>
<td>比较两个对象是否小于（默认用于<code>set</code>, <code>map</code>等）</td>
</tr>
<tr>
<td></td>
<td><code>greater&lt;T&gt;</code></td>
<td>比较两个对象是否大于</td>
</tr>
<tr>
<td></td>
<td>自定义函数对象</td>
<td>自定义比较或操作函数</td>
</tr>
<tr>
<td><strong>适配器（Adapters）</strong></td>
<td></td>
<td>修改已有接口以适应不同需求</td>
</tr>
<tr>
<td></td>
<td><code>reverse_iterator</code></td>
<td>反向迭代器，用于反向遍历容器</td>
</tr>
<tr>
<td></td>
<td><code>istream_iterator</code></td>
<td>读取输入流中的元素</td>
</tr>
<tr>
<td></td>
<td><code>ostream_iterator</code></td>
<td>将元素写入输出流</td>
</tr>
<tr>
<td><strong>分配器（Allocators）</strong></td>
<td></td>
<td>管理容器中的内存分配</td>
</tr>
<tr>
<td></td>
<td><code>allocator&lt;T&gt;</code></td>
<td>默认分配器，使用<code>new</code>和<code>delete</code></td>
</tr>
<tr>
<td></td>
<td>自定义分配器</td>
<td>根据特定需求管理内存</td>
</tr>
</tbody>
</table>
<h3 id="常用容器">常用容器</h3>
<h4 id="string容器">string容器</h4>
<h5 id="构造函数：">构造函数：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">string</span>();<span class="comment">//创建一个空的字符串 例如: string str;      </span></span><br><span class="line"><span class="built_in">string</span>(<span class="type">const</span> string&amp; str);<span class="comment">//使用一个string对象初始化另一个string对象</span></span><br><span class="line"><span class="built_in">string</span>(<span class="type">const</span> <span class="type">char</span>* s);<span class="comment">//使用字符串s初始化</span></span><br><span class="line"><span class="built_in">string</span>(<span class="type">int</span> n, <span class="type">char</span> c);<span class="comment">//使用n个字符c初始化 </span></span><br></pre></td></tr></table></figure>
<h5 id="基本赋值：">基本赋值：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string&amp; <span class="keyword">operator</span>=(<span class="type">const</span> <span class="type">char</span>* s);<span class="comment">//char*类型字符串 赋值给当前的字符串</span></span><br><span class="line">string&amp; <span class="keyword">operator</span>=(<span class="type">const</span> string &amp;s);<span class="comment">//把字符串s赋给当前的字符串</span></span><br><span class="line">string&amp; <span class="keyword">operator</span>=(<span class="type">char</span> c);<span class="comment">//字符赋值给当前的字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">assign</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span></span>;<span class="comment">//把字符串s赋给当前的字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">assign</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s, <span class="type">int</span> n)</span></span>;<span class="comment">//把字符串s的前n个字符赋给当前的字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">assign</span><span class="params">(<span class="type">const</span> string &amp;s)</span></span>;<span class="comment">//把字符串s赋给当前字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">assign</span><span class="params">(<span class="type">int</span> n, <span class="type">char</span> c)</span></span>;<span class="comment">//用n个字符c赋给当前字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">assign</span><span class="params">(<span class="type">const</span> string &amp;s, <span class="type">int</span> start, <span class="type">int</span> n)</span></span>;<span class="comment">//将s从start开始n个字符赋值给字符</span></span><br></pre></td></tr></table></figure>
<h5 id="存取字符：">存取字符：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span>&amp; <span class="keyword">operator</span>[](<span class="type">int</span> n);<span class="comment">//通过[]方式取字符</span></span><br><span class="line"><span class="function"><span class="type">char</span>&amp; <span class="title">at</span><span class="params">(<span class="type">int</span> n)</span></span>;<span class="comment">//通过at方法获取字符</span></span><br></pre></td></tr></table></figure>
<h5 id="拼接操作：">拼接操作：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string&amp; <span class="keyword">operator</span>+=(<span class="type">const</span> string&amp; str);<span class="comment">//重载+=操作符</span></span><br><span class="line">string&amp; <span class="keyword">operator</span>+=(<span class="type">const</span> <span class="type">char</span>* str);<span class="comment">//重载+=操作符</span></span><br><span class="line">string&amp; <span class="keyword">operator</span>+=(<span class="type">const</span> <span class="type">char</span> c);<span class="comment">//重载+=操作符</span></span><br><span class="line"><span class="function">string&amp; <span class="title">append</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span></span>;<span class="comment">//把字符串s连接到当前字符串结尾</span></span><br><span class="line"><span class="function">string&amp; <span class="title">append</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s, <span class="type">int</span> n)</span></span>;<span class="comment">//把字符串s的前n个字符连接到当前字符串结尾</span></span><br><span class="line"><span class="function">string&amp; <span class="title">append</span><span class="params">(<span class="type">const</span> string &amp;s)</span></span>;<span class="comment">//同operator+=()</span></span><br><span class="line"><span class="function">string&amp; <span class="title">append</span><span class="params">(<span class="type">const</span> string &amp;s, <span class="type">int</span> pos, <span class="type">int</span> n)</span></span>;<span class="comment">//把字符串s中从pos开始的n个字符连接到当前字符串结尾</span></span><br><span class="line"><span class="function">string&amp; <span class="title">append</span><span class="params">(<span class="type">int</span> n, <span class="type">char</span> c)</span></span>;<span class="comment">//在当前字符串结尾添加n个字符c</span></span><br></pre></td></tr></table></figure>
<h5 id="查找替换：">查找替换：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">const</span> string&amp; str, <span class="type">int</span> pos = <span class="number">0</span>)</span> <span class="type">const</span></span>; <span class="comment">//查找str第一次出现位置,从pos开始查找</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* s, <span class="type">int</span> pos = <span class="number">0</span>)</span> <span class="type">const</span></span>;  <span class="comment">//查找s第一次出现位置,从pos开始查找</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* s, <span class="type">int</span> pos, <span class="type">int</span> n)</span> <span class="type">const</span></span>;  <span class="comment">//从pos位置查找s的前n个字符第一次位置</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">const</span> <span class="type">char</span> c, <span class="type">int</span> pos = <span class="number">0</span>)</span> <span class="type">const</span></span>;  <span class="comment">//查找字符c第一次出现位置</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">rfind</span><span class="params">(<span class="type">const</span> string&amp; str, <span class="type">int</span> pos = npos)</span> <span class="type">const</span></span>;<span class="comment">//查找str最后一次位置,从pos开始查找</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">rfind</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* s, <span class="type">int</span> pos = npos)</span> <span class="type">const</span></span>;<span class="comment">//查找s最后一次出现位置,从pos开始查找</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">rfind</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* s, <span class="type">int</span> pos, <span class="type">int</span> n)</span> <span class="type">const</span></span>;<span class="comment">//从pos查找s的前n个字符最后一次位置</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">rfind</span><span class="params">(<span class="type">const</span> <span class="type">char</span> c, <span class="type">int</span> pos = <span class="number">0</span>)</span> <span class="type">const</span></span>; <span class="comment">//查找字符c最后一次出现位置</span></span><br><span class="line"><span class="function">string&amp; <span class="title">replace</span><span class="params">(<span class="type">int</span> pos, <span class="type">int</span> n, <span class="type">const</span> string&amp; str)</span></span>; <span class="comment">//替换从pos开始n个字符为字符串str</span></span><br><span class="line"><span class="function">string&amp; <span class="title">replace</span><span class="params">(<span class="type">int</span> pos, <span class="type">int</span> n, <span class="type">const</span> <span class="type">char</span>* s)</span></span>; <span class="comment">//替换从pos开始的n个字符为字符串s</span></span><br></pre></td></tr></table></figure>
<h5 id="比较操作：">比较操作：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">compare函数在&gt;时返回 1，&lt;时返回 -1，==时返回 0。</span></span><br><span class="line"><span class="comment">比较区分大小写，比较时参考字典顺序，排越前面的越小。</span></span><br><span class="line"><span class="comment">大写的A比小写的a小。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">compare</span><span class="params">(<span class="type">const</span> string &amp;s)</span> <span class="type">const</span></span>;<span class="comment">//与字符串s比较</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">compare</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *s)</span> <span class="type">const</span></span>;<span class="comment">//与字符串s比较</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="取出子串：">取出子串：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">string <span class="title">substr</span><span class="params">(<span class="type">int</span> pos = <span class="number">0</span>, <span class="type">int</span> n = npos)</span> <span class="type">const</span></span>;<span class="comment">//返回由pos开始的n个字符组成的字符串</span></span><br></pre></td></tr></table></figure>
<h5 id="插入删除：">插入删除：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">string&amp; <span class="title">insert</span><span class="params">(<span class="type">int</span> pos, <span class="type">const</span> <span class="type">char</span>* s)</span></span>; <span class="comment">//插入字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">insert</span><span class="params">(<span class="type">int</span> pos, <span class="type">const</span> string&amp; str)</span></span>; <span class="comment">//插入字符串</span></span><br><span class="line"><span class="function">string&amp; <span class="title">insert</span><span class="params">(<span class="type">int</span> pos, <span class="type">int</span> n, <span class="type">char</span> c)</span></span>;<span class="comment">//在指定位置插入n个字符c</span></span><br><span class="line"><span class="function">string&amp; <span class="title">erase</span><span class="params">(<span class="type">int</span> pos, <span class="type">int</span> n = npos)</span></span>;<span class="comment">//删除从Pos开始的n个字符 </span></span><br></pre></td></tr></table></figure>
<h5 id="c-style转换：">c-style转换：</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//string 转 char*</span></span><br><span class="line">string str = <span class="string">&quot;it&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span>* cstr = str.<span class="built_in">c_str</span>();</span><br><span class="line"><span class="comment">//char* 转 string </span></span><br><span class="line"><span class="type">char</span>* s = <span class="string">&quot;it&quot;</span>;</span><br><span class="line"><span class="function">string <span class="title">str</span><span class="params">(s)</span></span>;</span><br></pre></td></tr></table></figure>
<h4 id="vector容器">vector容器</h4>
<h5 id="构造函数">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;T&gt; v; <span class="comment">//采用模板实现类实现，默认构造函数</span></span><br><span class="line"><span class="built_in">vector</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>());<span class="comment">//将v[begin(), end())区间中的元素拷贝给本身。</span></span><br><span class="line"><span class="built_in">vector</span>(n, elem);<span class="comment">//构造函数将n个elem拷贝给本身。</span></span><br><span class="line"><span class="built_in">vector</span>(<span class="type">const</span> vector &amp;vec);<span class="comment">//拷贝构造函数。</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">assign</span>(beg, end);<span class="comment">//将[beg, end)区间中的数据拷贝赋值给本身。</span></span><br><span class="line"><span class="built_in">assign</span>(n, elem);<span class="comment">//将n个elem拷贝赋值给本身。</span></span><br><span class="line">vector&amp; <span class="keyword">operator</span>=(<span class="type">const</span> vector  &amp;vec);<span class="comment">//重载等号操作符</span></span><br><span class="line"><span class="built_in">swap</span>(vec);<span class="comment">// 将vec与本身的元素互换。</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">size</span>();<span class="comment">//返回容器中元素的个数</span></span><br><span class="line"><span class="built_in">empty</span>();<span class="comment">//判断容器是否为空</span></span><br><span class="line"><span class="built_in">resize</span>(<span class="type">int</span> num);<span class="comment">//重新指定容器的长度为num，若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。</span></span><br><span class="line"><span class="built_in">resize</span>(<span class="type">int</span> num, elem);<span class="comment">//重新指定容器的长度为num，若容器变长，则以elem值填充新位置。如果容器变短，则末尾超出容器长&gt;度的元素被删除。</span></span><br><span class="line"><span class="built_in">capacity</span>();<span class="comment">//容器的容量</span></span><br><span class="line"><span class="built_in">reserve</span>(<span class="type">int</span> len);<span class="comment">//容器预留len个元素长度，预留位置不初始化，元素不可访问。</span></span><br></pre></td></tr></table></figure>
<h5 id="数据存取">数据存取</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">at</span>(<span class="type">int</span> idx); <span class="comment">//返回索引idx所指的数据，如果idx越界，抛出out_of_range异常。</span></span><br><span class="line"><span class="keyword">operator</span>[];<span class="comment">//返回索引idx所指的数据，越界时，运行直接报错</span></span><br><span class="line"><span class="built_in">front</span>();<span class="comment">//返回容器中第一个数据元素</span></span><br><span class="line"><span class="built_in">back</span>();<span class="comment">//返回容器中最后一个数据元素</span></span><br></pre></td></tr></table></figure>
<h5 id="插入删除">插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">insert</span>(const_iterator pos, <span class="type">int</span> count,ele);<span class="comment">//迭代器指向位置pos插入count个元素ele.</span></span><br><span class="line"><span class="built_in">push_back</span>(ele); <span class="comment">//尾部插入元素ele</span></span><br><span class="line"><span class="built_in">pop_back</span>();<span class="comment">//删除最后一个元素</span></span><br><span class="line"><span class="built_in">erase</span>(const_iterator start, const_iterator end);<span class="comment">//删除迭代器从start到end之间的元素</span></span><br><span class="line"><span class="built_in">erase</span>(const_iterator pos);<span class="comment">//删除迭代器指向的元素</span></span><br><span class="line"><span class="built_in">clear</span>();<span class="comment">//删除容器中所有元素</span></span><br></pre></td></tr></table></figure>
<h4 id="deque容器">deque容器</h4>
<h5 id="构造函数-2">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">deque&lt;T&gt; deqT;<span class="comment">//默认构造形式</span></span><br><span class="line"><span class="built_in">deque</span>(beg, end);<span class="comment">//构造函数将[beg, end)区间中的元素拷贝给本身。</span></span><br><span class="line"><span class="built_in">deque</span>(n, elem);<span class="comment">//构造函数将n个elem拷贝给本身。</span></span><br><span class="line"><span class="built_in">deque</span>(<span class="type">const</span> deque &amp;deq);<span class="comment">//拷贝构造函数。</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-2">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">assign</span>(beg, end);<span class="comment">//将[beg, end)区间中的数据拷贝赋值给本身。</span></span><br><span class="line"><span class="built_in">assign</span>(n, elem);<span class="comment">//将n个elem拷贝赋值给本身。</span></span><br><span class="line">deque&amp; <span class="keyword">operator</span>=(<span class="type">const</span> deque &amp;deq); <span class="comment">//重载等号操作符 </span></span><br><span class="line"><span class="built_in">swap</span>(deq);<span class="comment">// 将deq与本身的元素互换</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-2">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">deque.<span class="built_in">size</span>();<span class="comment">//返回容器中元素的个数</span></span><br><span class="line">deque.<span class="built_in">empty</span>();<span class="comment">//判断容器是否为空</span></span><br><span class="line">deque.<span class="built_in">resize</span>(num);<span class="comment">//重新指定容器的长度为num,若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。</span></span><br><span class="line">deque.<span class="built_in">resize</span>(num, elem); <span class="comment">//重新指定容器的长度为num,若容器变长，则以elem值填充新位置,如果容器变短，则末尾超出容器长度的元素被删除。</span></span><br></pre></td></tr></table></figure>
<h5 id="插入删除-2">插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">insert</span>(pos,elem);<span class="comment">//在pos位置插入一个elem元素的拷贝，返回新数据的位置。</span></span><br><span class="line"><span class="built_in">insert</span>(pos,n,elem);<span class="comment">//在pos位置插入n个elem数据，无返回值。</span></span><br><span class="line"><span class="built_in">insert</span>(pos,beg,end);<span class="comment">//在pos位置插入[beg,end)区间的数据，无返回值。</span></span><br><span class="line"><span class="built_in">clear</span>();<span class="comment">//移除容器的所有数据</span></span><br><span class="line"><span class="built_in">erase</span>(beg,end);<span class="comment">//删除[beg,end)区间的数据，返回下一个数据的位置。</span></span><br><span class="line"><span class="built_in">erase</span>(pos);<span class="comment">//删除pos位置的数据，返回下一个数据的位置。</span></span><br></pre></td></tr></table></figure>
<h5 id="数据存取-2">数据存取</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">at</span>(idx);<span class="comment">//返回索引idx所指的数据，如果idx越界，抛出out_of_range。</span></span><br><span class="line"><span class="keyword">operator</span>[];<span class="comment">//返回索引idx所指的数据，如果idx越界，不抛出异常，直接出错。</span></span><br><span class="line"><span class="built_in">front</span>();<span class="comment">//返回第一个数据。</span></span><br><span class="line"><span class="built_in">back</span>();<span class="comment">//返回最后一个数据</span></span><br></pre></td></tr></table></figure>
<h5 id="双端插入删除">双端插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push_back</span>(elem);<span class="comment">//在容器尾部添加一个数据</span></span><br><span class="line"><span class="built_in">push_front</span>(elem);<span class="comment">//在容器头部插入一个数据</span></span><br><span class="line"><span class="built_in">pop_back</span>();<span class="comment">//删除容器最后一个数据</span></span><br><span class="line"><span class="built_in">pop_front</span>();<span class="comment">//删除容器第一个数据</span></span><br></pre></td></tr></table></figure>
<h4 id="stack容器">stack容器</h4>
<h5 id="构造函数-3">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">stack&lt;T&gt; stkT;<span class="comment">//stack采用模板类实现， stack对象的默认构造形式： </span></span><br><span class="line"><span class="built_in">stack</span>(<span class="type">const</span> stack &amp;stk);<span class="comment">//拷贝构造函数</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-3">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">stack&amp; <span class="keyword">operator</span>=(<span class="type">const</span> stack &amp;stk);<span class="comment">//重载等号操作符</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-3">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push</span>(elem);<span class="comment">//向栈顶添加元素</span></span><br><span class="line"><span class="built_in">pop</span>();<span class="comment">//从栈顶移除第一个元素</span></span><br><span class="line"><span class="built_in">top</span>();<span class="comment">//返回栈顶元素</span></span><br></pre></td></tr></table></figure>
<h5 id="数据存取-3">数据存取</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push</span>(elem);<span class="comment">//向栈顶添加元素</span></span><br><span class="line"><span class="built_in">pop</span>();<span class="comment">//从栈顶移除第一个元素</span></span><br><span class="line"><span class="built_in">top</span>();<span class="comment">//返回栈顶元素</span></span><br></pre></td></tr></table></figure>
<h4 id="queue容器">queue容器</h4>
<h5 id="构造函数-4">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">queue&lt;T&gt; queT;<span class="comment">//queue采用模板类实现，queue对象的默认构造形式：</span></span><br><span class="line"><span class="built_in">queue</span>(<span class="type">const</span> queue &amp;que);<span class="comment">//拷贝构造函数</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-4">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">queue&amp; <span class="keyword">operator</span>=(<span class="type">const</span> queue &amp;que);<span class="comment">//重载等号操作符</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-4">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">queue&amp; <span class="keyword">operator</span>=(<span class="type">const</span> queue &amp;que);<span class="comment">//重载等号操作符</span></span><br></pre></td></tr></table></figure>
<h5 id="存取插入删除">存取插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push</span>(elem);<span class="comment">//往队尾添加元素</span></span><br><span class="line"><span class="built_in">pop</span>();<span class="comment">//从队头移除第一个元素</span></span><br><span class="line"><span class="built_in">back</span>();<span class="comment">//返回最后一个元素</span></span><br><span class="line"><span class="built_in">front</span>();<span class="comment">//返回第一个元素</span></span><br></pre></td></tr></table></figure>
<h4 id="list容器">list容器</h4>
<h5 id="构造函数-5">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">list&lt;T&gt; lstT;<span class="comment">//list采用采用模板类实现,对象的默认构造形式：</span></span><br><span class="line"><span class="built_in">list</span>(beg,end);<span class="comment">//构造函数将[beg, end)区间中的元素拷贝给本身。</span></span><br><span class="line"><span class="built_in">list</span>(n,elem);<span class="comment">//构造函数将n个elem拷贝给本身。</span></span><br><span class="line"><span class="built_in">list</span>(<span class="type">const</span> list &amp;lst);<span class="comment">//拷贝构造函数。</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-5">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">assign</span>(beg, end);<span class="comment">//将[beg, end)区间中的数据拷贝赋值给本身。</span></span><br><span class="line"><span class="built_in">assign</span>(n, elem);<span class="comment">//将n个elem拷贝赋值给本身。</span></span><br><span class="line">list&amp; <span class="keyword">operator</span>=(<span class="type">const</span> list &amp;lst);<span class="comment">//重载等号操作符</span></span><br><span class="line"><span class="built_in">swap</span>(lst);<span class="comment">//将lst与本身的元素互换。</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-5">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">size</span>();<span class="comment">//返回容器中元素的个数</span></span><br><span class="line"><span class="built_in">empty</span>();<span class="comment">//判断容器是否为空</span></span><br><span class="line"><span class="built_in">resize</span>(num);<span class="comment">//重新指定容器的长度为num，</span></span><br><span class="line">若容器变长，则以默认值填充新位置。</span><br><span class="line">如果容器变短，则末尾超出容器长度的元素被删除。</span><br><span class="line"><span class="built_in">resize</span>(num, elem);<span class="comment">//重新指定容器的长度为num，</span></span><br><span class="line">若容器变长，则以elem值填充新位置。</span><br><span class="line">如果容器变短，则末尾超出容器长度的元素被删除。</span><br></pre></td></tr></table></figure>
<h5 id="插入删除-3">插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push_back</span>(elem);<span class="comment">//在容器尾部加入一个元素</span></span><br><span class="line"><span class="built_in">pop_back</span>();<span class="comment">//删除容器中最后一个元素</span></span><br><span class="line"><span class="built_in">push_front</span>(elem);<span class="comment">//在容器开头插入一个元素</span></span><br><span class="line"><span class="built_in">pop_front</span>();<span class="comment">//从容器开头移除第一个元素</span></span><br><span class="line"><span class="built_in">insert</span>(pos,elem);<span class="comment">//在pos位置插elem元素的拷贝，返回新数据的位置。</span></span><br><span class="line"><span class="built_in">insert</span>(pos,n,elem);<span class="comment">//在pos位置插入n个elem数据，无返回值。</span></span><br><span class="line"><span class="built_in">insert</span>(pos,beg,end);<span class="comment">//在pos位置插入[beg,end)区间的数据，无返回值。</span></span><br><span class="line"><span class="built_in">clear</span>();<span class="comment">//移除容器的所有数据</span></span><br><span class="line"><span class="built_in">erase</span>(beg,end);<span class="comment">//删除[beg,end)区间的数据，返回下一个数据的位置。</span></span><br><span class="line"><span class="built_in">erase</span>(pos);<span class="comment">//删除pos位置的数据，返回下一个数据的位置。</span></span><br><span class="line"><span class="built_in">remove</span>(elem);<span class="comment">//删除容器中所有与elem值匹配的元素。</span></span><br></pre></td></tr></table></figure>
<h5 id="数据存取-4">数据存取</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">front</span>();<span class="comment">//返回第一个元素。</span></span><br><span class="line"><span class="built_in">back</span>();<span class="comment">//返回最后一个元素。</span></span><br></pre></td></tr></table></figure>
<h5 id="反转排序">反转排序</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">reverse</span>();<span class="comment">//反转链表，比如lst包含1,3,5元素，运行此方法后，lst就包含5,3,1元素。</span></span><br><span class="line"><span class="built_in">sort</span>(); <span class="comment">//list排序</span></span><br></pre></td></tr></table></figure>
<h4 id="set-multiset容器">set/multiset容器</h4>
<h5 id="构造函数-6">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">set&lt;T&gt; st;<span class="comment">//set默认构造函数：</span></span><br><span class="line">mulitset&lt;T&gt; mst; <span class="comment">//multiset默认构造函数: </span></span><br><span class="line"><span class="built_in">set</span>(<span class="type">const</span> set &amp;st);<span class="comment">//拷贝构造函数</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-6">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">set&amp; <span class="keyword">operator</span>=(<span class="type">const</span> set &amp;st);<span class="comment">//重载等号操作符</span></span><br><span class="line"><span class="built_in">swap</span>(st);<span class="comment">//交换两个集合容器</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-6">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">set&amp; <span class="keyword">operator</span>=(<span class="type">const</span> set &amp;st);<span class="comment">//重载等号操作符</span></span><br><span class="line"><span class="built_in">swap</span>(st);<span class="comment">//交换两个集合容器</span></span><br></pre></td></tr></table></figure>
<h5 id="插入删除-4">插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">insert</span>(elem);<span class="comment">//在容器中插入元素。</span></span><br><span class="line"><span class="built_in">clear</span>();<span class="comment">//清除所有元素</span></span><br><span class="line"><span class="built_in">erase</span>(pos);<span class="comment">//删除pos迭代器所指的元素，返回下一个元素的迭代器。</span></span><br><span class="line"><span class="built_in">erase</span>(beg, end);<span class="comment">//删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。</span></span><br><span class="line"><span class="built_in">erase</span>(elem);<span class="comment">//删除容器中值为elem的元素。</span></span><br></pre></td></tr></table></figure>
<h5 id="查找操作">查找操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">find</span>(key);<span class="comment">//查找键key是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end();</span></span><br><span class="line"><span class="built_in">count</span>(key);<span class="comment">//查找键key的元素个数</span></span><br><span class="line"><span class="built_in">lower_bound</span>(keyElem);<span class="comment">//返回第一个key&gt;=keyElem元素的迭代器。</span></span><br><span class="line"><span class="built_in">upper_bound</span>(keyElem);<span class="comment">//返回第一个key&gt;keyElem元素的迭代器。</span></span><br><span class="line"><span class="built_in">equal_range</span>(keyElem);<span class="comment">//返回容器中key与keyElem相等的上下限的两个迭代器。</span></span><br></pre></td></tr></table></figure>
<h5 id="对组（pair）">对组（pair）</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//第一种方法创建一个对组</span></span><br><span class="line"><span class="function">pair&lt;string, <span class="type">int</span>&gt; <span class="title">pair1</span><span class="params">(string(<span class="string">&quot;name&quot;</span>), <span class="number">20</span>)</span></span>;</span><br><span class="line">cout &lt;&lt; pair1.first &lt;&lt; endl; <span class="comment">//访问pair第一个值</span></span><br><span class="line">cout &lt;&lt; pair1.second &lt;&lt; endl;<span class="comment">//访问pair第二个值</span></span><br><span class="line"><span class="comment">//第二种</span></span><br><span class="line">pair&lt;string, <span class="type">int</span>&gt; pair2 = <span class="built_in">make_pair</span>(<span class="string">&quot;name&quot;</span>, <span class="number">30</span>);</span><br><span class="line">cout &lt;&lt; pair2.first &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; pair2.second &lt;&lt; endl;</span><br><span class="line"><span class="comment">//pair=赋值</span></span><br><span class="line">pair&lt;string, <span class="type">int</span>&gt; pair3 = pair2;</span><br><span class="line">cout &lt;&lt; pair3.first &lt;&lt; endl;</span><br><span class="line">cout &lt;&lt; pair3.second &lt;&lt; endl;</span><br></pre></td></tr></table></figure>
<h4 id="map-multimap">map/multimap</h4>
<h5 id="构造函数-7">构造函数</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">map&lt;T1, T2&gt; mapTT;<span class="comment">//map默认构造函数: </span></span><br><span class="line"><span class="built_in">map</span>(<span class="type">const</span> map &amp;mp);<span class="comment">//拷贝构造函数</span></span><br></pre></td></tr></table></figure>
<h5 id="赋值操作-7">赋值操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">map&amp; <span class="keyword">operator</span>=(<span class="type">const</span> map &amp;mp);<span class="comment">//重载等号操作符</span></span><br><span class="line"><span class="built_in">swap</span>(mp);<span class="comment">//交换两个集合容器</span></span><br></pre></td></tr></table></figure>
<h5 id="大小操作-7">大小操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">size</span>();<span class="comment">//返回容器中元素的数目</span></span><br><span class="line"><span class="built_in">empty</span>();<span class="comment">//判断容器是否为空</span></span><br></pre></td></tr></table></figure>
<h5 id="插入删除-5">插入删除</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">map.<span class="built_in">insert</span>(...); <span class="comment">//往容器插入元素，返回pair&lt;iterator,bool&gt;</span></span><br><span class="line">map&lt;<span class="type">int</span>, string&gt; mapStu;</span><br><span class="line"><span class="comment">// 第一种 通过pair的方式插入对象</span></span><br><span class="line">mapStu.<span class="built_in">insert</span>(<span class="built_in">pair</span>&lt;<span class="type">int</span>, string&gt;(<span class="number">3</span>, <span class="string">&quot;小张&quot;</span>));</span><br><span class="line"><span class="comment">// 第二种 通过pair的方式插入对象</span></span><br><span class="line">mapStu.<span class="built_in">inset</span>(<span class="built_in">make_pair</span>(<span class="number">-1</span>, <span class="string">&quot;校长&quot;</span>));</span><br><span class="line"><span class="comment">// 第三种 通过value_type的方式插入对象</span></span><br><span class="line">mapStu.<span class="built_in">insert</span>(map&lt;<span class="type">int</span>, string&gt;::<span class="built_in">value_type</span>(<span class="number">1</span>, <span class="string">&quot;小李&quot;</span>));</span><br><span class="line"><span class="comment">// 第四种 通过数组的方式插入值</span></span><br><span class="line">mapStu[<span class="number">3</span>] = <span class="string">&quot;小刘&quot;</span>;</span><br><span class="line">mapStu[<span class="number">5</span>] = <span class="string">&quot;小王&quot;</span>;</span><br><span class="line"><span class="built_in">clear</span>();<span class="comment">//删除所有元素</span></span><br><span class="line"><span class="built_in">erase</span>(pos);<span class="comment">//删除pos迭代器所指的元素，返回下一个元素的迭代器。</span></span><br><span class="line"><span class="built_in">erase</span>(beg,end);<span class="comment">//删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。</span></span><br><span class="line"><span class="built_in">erase</span>(keyElem);<span class="comment">//删除容器中key为keyElem的对组。</span></span><br></pre></td></tr></table></figure>
<h5 id="查找操作-2">查找操作</h5>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">find</span>(key);<span class="comment">//查找键key是否存在,若存在，返回该键的元素的迭代器；/若不存在，返回map.end();</span></span><br><span class="line"><span class="built_in">count</span>(keyElem);<span class="comment">//返回容器中key为keyElem的对组个数。对map来说，要么是0，要么是1。对multimap来说，值可能大于1。</span></span><br><span class="line"><span class="built_in">lower_bound</span>(keyElem);<span class="comment">//返回第一个key&gt;=keyElem元素的迭代器。</span></span><br><span class="line"><span class="built_in">upper_bound</span>(keyElem);<span class="comment">//返回第一个key&gt;keyElem元素的迭代器。</span></span><br><span class="line"><span class="built_in">equal_range</span>(keyElem);<span class="comment">//返回容器中key与keyElem相等的上下限的两个迭代器。</span></span><br></pre></td></tr></table></figure>
<h4 id=""></h4>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title>Per_FedAVG源码分析</title>
    <url>/2024/06/27/Per-FedAVG%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h3 id="Per-FeAVG源码分析——根目录下：">Per_FeAVG源码分析——根目录下：</h3>
<p>KarhouTam的Per_FedAVG.源码链接：<a href="https://github.com/KarhouTam/Per-FedAvg">请使用到的点个star</a></p>
<h4 id="utils-py"><a href="http://utils.py">utils.py</a></h4>
<h5 id="函数：get-args（）">函数：get_args（）</h5>
<p>功能：用于加载参数:使用ArgumentParser()输入了<strong>联邦参数</strong>，<strong>模型参数</strong>，<strong>其他参数</strong>三类参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Iterator, <span class="type">Tuple</span>, <span class="type">Union</span></span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    <span class="comment">##‘--alpha’表示参数名称，type代表参数类型，default代表默认值设置，help则是对alpha的描述性解释。</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--alpha&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-2</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--beta&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1e-3</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--global_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--local_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--pers_epochs&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">        default=<span class="number">1</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;Indicate how many data batches would be used for personalization. Negatives means that equal to train phase.&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--hf&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">        default=<span class="number">0</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;0 for performing Per-FedAvg(FO), others for Per-FedAvg(HF)&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">40</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--valset_ratio&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">        default=<span class="number">0.1</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;Proportion of val set in the entire client local dataset&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, choices=[<span class="string">&quot;mnist&quot;</span>, <span class="string">&quot;cifar&quot;</span>], default=<span class="string">&quot;mnist&quot;</span></span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--client_num_per_round&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--seed&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">17</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--gpu&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">        default=<span class="number">1</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;Non-zero value for using gpu, 0 for using cpu&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--eval_while_training&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">        default=<span class="number">1</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;Non-zero value for performing local evaluation before and after local training&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--log&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args() <span class="comment">#解析了命令行参数，并将解析结果作为函数的返回值，以便在其他地方可以使用参数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="函数：eval（）">函数：eval（）</h5>
<p>功能：用于在PyTorch中评估给定模型的性能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad() </span><span class="comment">#这个装饰器确保在评估模型时不会计算梯度，从而节省内存和计算资源。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model: torch.nn.Module,<span class="comment">#评价的模型</span></span></span><br><span class="line"><span class="params">    dataloader: torch.utils.data.DataLoader,<span class="comment">#数据集加载器</span></span></span><br><span class="line"><span class="params">    criterion: <span class="type">Union</span>[torch.nn.MSELoss, torch.nn.CrossEntropyLoss],<span class="comment">#损失函数，可以是均方误差（MSE）或交叉熵损失。</span></span></span><br><span class="line"><span class="params">    device=torch.device(<span class="params"><span class="string">&quot;cpu&quot;</span></span>),<span class="comment">#用于运行模型的设备（默认为cpu）</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span><br><span class="line">    <span class="comment">#将模型设置为评估模式，确保如Dropout或BatchNorm这样的层在评估时以不同的方式工作。</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span></span><br><span class="line">    acc = <span class="number">0</span></span><br><span class="line">    <span class="comment">#对于数据加载器中的每一批数据，计算损失和准确率。</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> dataloader:</span><br><span class="line">        x, y = x.to(device), y.to(device)</span><br><span class="line">        logit = model(x)</span><br><span class="line">        <span class="comment"># total_loss += criterion(logit, y) / y.size(-1)</span></span><br><span class="line">        total_loss += criterion(logit, y) <span class="comment">#使用给定的损失函数计算预测（logit）和真实标签（y）之间的损失。</span></span><br><span class="line">        pred = torch.softmax(logit, -<span class="number">1</span>).argmax(-<span class="number">1</span>)<span class="comment">#使用 torch.softmax 和 argmax 获取预测的类别索引，然后与真实标签比较，统计正确的预测。</span></span><br><span class="line">        acc += torch.eq(pred, y).<span class="built_in">int</span>().<span class="built_in">sum</span>()</span><br><span class="line">        num_samples += y.size(-<span class="number">1</span>)</span><br><span class="line">    model.train()<span class="comment">#在评估结束后将模型重置为训练模式，尽管这通常不是必需的，因为下一个使用模型的操作可能会自动设置它。</span></span><br><span class="line">    <span class="keyword">return</span> total_loss, acc / num_samples</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="函数：fix-random-seed-seed-int">函数：fix_random_seed(seed: int)</h5>
<p>作用：设置随机种子以确保结果的可复现性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fix_random_seed</span>(<span class="params">seed: <span class="built_in">int</span></span>):</span><br><span class="line">    torch.cuda.empty_cache()<span class="comment">#这个函数会清空CUDA缓存。</span></span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)<span class="comment">#这分别设置CPU和GPU上的随机种子，以确保PyTorch操作的随机性是可复现的。这是正确的。</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)<span class="comment">#这两个函数分别设置Python标准库中的random模块和NumPy库中的随机数生成器的种子。这也是为了确保其他库中的随机操作是可复现的。</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span><span class="comment">#当你设置deterministic=True时，你告诉cuDNN（CUDA Deep Neural Network library）在卷积操作中使用确定性的算法，而不是可能更快但不太确定的算法。这有助于确保即使在GPU上，结果也是可复现的。</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">True</span><span class="comment">#这个设置告诉cuDNN为特定的配置自动寻找最快的卷积算法。但是，当benchmark=True时，cuDNN会尝试不同的算法并保留最佳的一个，这可能会导致结果不可复现，因为每次运行都可能选择不同的算法。</span></span><br></pre></td></tr></table></figure>
<h4 id="model-py"><a href="http://model.py">model.py</a></h4>
<h5 id="函数：elu-nn-Module">函数：elu(nn.Module)</h5>
<p>作用：它实现了指数线性单元（Exponential Linear Unit, ELU）激活函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">elu</span>(nn.Module):<span class="comment">#继承自nn.Module的类elu。</span></span><br><span class="line">    <span class="comment">#调用了父类nn.Module的__init__方法来确保基类的初始化。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(elu, self).__init__()</span><br><span class="line">	<span class="comment">#实现了ELU激活函数。对于输入x，如果x大于或等于0，则返回x本身；否则，返回0.2 * (torch.exp(x) - 1)。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.where(x &gt;= <span class="number">0</span>, x, <span class="number">0.2</span> * (torch.exp(x) - <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h5 id="类：linear-nn-Module">类：linear(nn.Module)</h5>
<p>作用：<code>__init__</code>方法用于初始化权重（<code>w</code>）和偏置（<code>b</code>），而<code>forward</code>方法定义了数据通过网络层的前向传播过程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">linear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_c, out_c</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(linear, self).__init__()</span><br><span class="line">        <span class="comment">#使用了torch.randn(out_c, in_c) * torch.sqrt(torch.tensor(2 / in_c))来初始化权重，这是He初始化（也称为Kaiming初始化）的一个变种，它通常用于ReLU或其变种激活函数。</span></span><br><span class="line">        self.w = nn.Parameter(</span><br><span class="line">            torch.randn(out_c, in_c) * torch.sqrt(torch.tensor(<span class="number">2</span> / in_c))</span><br><span class="line">        )</span><br><span class="line">        self.b = nn.Parameter(torch.randn(out_c))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> F.linear(x, self.w, self.b)</span><br></pre></td></tr></table></figure>
<h5 id="类：MLP-MNIST">类：MLP_MNIST</h5>
<p>作用：构建不同类型的神经网络模型，分别是MLP（多层感知机）、CNNMnist（用于MNIST手写数字数据集的卷积神经网络）和CNNCifar（用于CIFAR-10数据集的卷积神经网络）。实现了神经网络的前向传播过程，并用于分类任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP_MNIST</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(MLP_MNIST, self).__init__()</span><br><span class="line">        self.fc1 = linear(<span class="number">28</span> * <span class="number">28</span>, <span class="number">80</span>)</span><br><span class="line">        self.fc2 = linear(<span class="number">80</span>, <span class="number">60</span>)</span><br><span class="line">        self.fc3 = linear(<span class="number">60</span>, <span class="number">10</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.activation = elu()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP_CIFAR10</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(MLP_CIFAR10, self).__init__()</span><br><span class="line">        self.fc1 = linear(<span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>, <span class="number">80</span>)</span><br><span class="line">        self.fc2 = linear(<span class="number">80</span>, <span class="number">60</span>)</span><br><span class="line">        self.fc3 = linear(<span class="number">60</span>, <span class="number">10</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.activation = elu()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h5 id="类：MLP-CIFAR10">类：MLP_CIFAR10</h5>
<p>作用：构建不同类型的神经网络模型，分别是MLP（多层感知机）、CNNMnist（用于MNIST手写数字数据集的卷积神经网络）和CNNCifar（用于CIFAR-10数据集的卷积神经网络）。实现了神经网络的前向传播过程，并用于分类任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP_CIFAR10</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(MLP_CIFAR10, self).__init__()</span><br><span class="line">        self.fc1 = linear(<span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>, <span class="number">80</span>)</span><br><span class="line">        self.fc2 = linear(<span class="number">80</span>, <span class="number">60</span>)</span><br><span class="line">        self.fc3 = linear(<span class="number">60</span>, <span class="number">10</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.activation = elu()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.activation(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h5 id="字典：MODEL-DICT">字典：MODEL_DICT</h5>
<p>作用：关联键<code>&quot;mnist&quot;</code>和<code>&quot;cifar&quot;</code>到它们各自的多层感知机（MLP）模型类<code>MLP_MNIST</code>和<code>MLP_CIFAR10</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MODEL_DICT = &#123;<span class="string">&quot;mnist&quot;</span>: MLP_MNIST, <span class="string">&quot;cifar&quot;</span>: MLP_CIFAR10&#125;</span><br></pre></td></tr></table></figure>
<h5 id="函数：get-model-dataset-device">函数：get_model(dataset, device)</h5>
<p>作用：根据数据集名称从<code>MODEL_DICT</code>字典中获取相应的模型类，并实例化模型，然后将模型移动到指定的设备上（CPU或GPU）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">dataset, device</span>):</span><br><span class="line">    <span class="keyword">return</span> MODEL_DICT[dataset]().to(device)</span><br></pre></td></tr></table></figure>
<h4 id="perfedavg-py"><a href="http://perfedavg.py">perfedavg.py</a></h4>
<h5 id="函数：init">函数：<strong>init</strong>()</h5>
<p>作用：类的初始化方法，用于配置和初始化类的实例变量。该方法接收多个参数，包括客户端ID、学习率参数（alpha和beta，可能是某种优化算法中的参数，如Momentum或Adam中的beta1和beta2）、全局模型、损失函数、批量大小、数据集名称、本地训练轮数、验证集比例、日志记录器和GPU设备ID。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    client_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    alpha: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">    beta: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">    global_model: torch.nn.Module,</span></span><br><span class="line"><span class="params">    criterion: <span class="type">Union</span>[torch.nn.CrossEntropyLoss, torch.nn.MSELoss],</span></span><br><span class="line"><span class="params">    batch_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    dataset: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">    local_epochs: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    valset_ratio: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">    logger: rich.console.Console,</span></span><br><span class="line"><span class="params">    gpu: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="comment">#设备选择：根据传入的gpu参数和torch.cuda.is_available()的结果，选择使用CPU还是GPU进行计算。</span></span><br><span class="line">    <span class="keyword">if</span> gpu <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">        self.device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="comment">#日志记录器：将传入的logger实例保存在类的实例变量中，以便在类的其他方法中使用。</span></span><br><span class="line">    self.logger = logger</span><br><span class="line">	<span class="comment">#本地训练参数：保存了本地训练轮数（local_epochs）和损失函数（criterion）。</span></span><br><span class="line">    self.local_epochs = local_epochs</span><br><span class="line">    self.criterion = criterion</span><br><span class="line">    <span class="comment">#客户端ID和模型：保存了客户端ID（client_id）和全局模型的深拷贝（global_model）。</span></span><br><span class="line">    self.<span class="built_in">id</span> = client_id</span><br><span class="line">    self.model = deepcopy(global_model)</span><br><span class="line">    <span class="comment">#学习率参数：保存了alpha和beta参数，这些参数可能是优化算法的一部分。</span></span><br><span class="line">    self.alpha = alpha</span><br><span class="line">    self.beta = beta</span><br><span class="line">    <span class="comment">#数据加载器：调用get_dataloader函数来获取训练和验证的数据加载器（trainloader和valloader）。这个函数根据数据集名称、客户端ID、批量大小和验证集比例来返回相应的数据加载器。</span></span><br><span class="line">    self.trainloader, self.valloader = get_dataloader(</span><br><span class="line">        dataset, client_id, batch_size, valset_ratio</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#迭代训练加载器：将训练数据加载器转换为迭代器并保存在iter_trainloader中。这样做可能是为了在类的其他方法中方便地从训练集中获取批量数据。</span></span><br><span class="line">    self.iter_trainloader = <span class="built_in">iter</span>(self.trainloader)</span><br></pre></td></tr></table></figure>
<h5 id="函数：get-data-batch-self">函数：get_data_batch(self)</h5>
<p>作用：用于从训练数据加载器中获取下一批数据，并处理<code>StopIteration</code>异常（当迭代器耗尽时触发）。当<code>iter_trainloader</code>中的数据被完全迭代一遍后，该方法会重新初始化迭代器并获取新的数据批次。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_data_batch</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment">#尝试获取数据：try块尝试从self.iter_trainloader（一个迭代器）中获取下一批数据（x为输入数据，y为标签）</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        x, y = <span class="built_in">next</span>(self.iter_trainloader)</span><br><span class="line">     <span class="comment">#异常处理：</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        self.iter_trainloader = <span class="built_in">iter</span>(self.trainloader)<span class="comment">#重新初始化iter_trainloader，通过调用iter(self.trainloader)来创建一个新的迭代器。</span></span><br><span class="line">        x, y = <span class="built_in">next</span>(self.iter_trainloader)<span class="comment">#再次尝试从新的迭代器中获取下一批数据。</span></span><br><span class="line">	<span class="comment">#无论数据是直接从原始迭代器中获取，还是通过重新初始化迭代器后获取，都会将数据（x和y）移动到self.device（即CPU或GPU）上，并返回它们。</span></span><br><span class="line">    <span class="keyword">return</span> x.to(self.device), y.to(self.device)</span><br></pre></td></tr></table></figure>
<h5 id="函数：train（）">函数：train（）</h5>
<p>作用：是一个用于在本地客户端上训练模型的函数。该方法接收全局模型、一个布尔值<code>hessian_free</code>（用于指示是否使用Hessian-free优化）和一个布尔值<code>eval_while_training</code>（用于指示是否在训练前后评估模型性能）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    global_model: torch.nn.Module,</span></span><br><span class="line"><span class="params">    hessian_free=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    eval_while_training=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    self.model.load_state_dict(global_model.state_dict())</span><br><span class="line">    <span class="comment">#训练前评估（可选）：如果eval_while_training为True，则在训练开始前使用utils.eval函数评估模型在验证集上的性能，并保存损失和准确率。</span></span><br><span class="line">    <span class="keyword">if</span> eval_while_training:</span><br><span class="line">        loss_before, acc_before = utils.<span class="built_in">eval</span>(</span><br><span class="line">            self.model, self.valloader, self.criterion, self.device</span><br><span class="line">        )</span><br><span class="line">    <span class="comment">#执行训练：调用_train方法</span></span><br><span class="line">    self._train(hessian_free)</span><br><span class="line">    </span><br><span class="line">	<span class="comment">#训练后评估（可选）：如果eval_while_training为True，则在训练结束后再次使用utils.eval函数评估模型在验证集上的性能，并保存损失和准确率。</span></span><br><span class="line">    <span class="keyword">if</span> eval_while_training:</span><br><span class="line">        loss_after, acc_after = utils.<span class="built_in">eval</span>(</span><br><span class="line">            self.model, self.valloader, self.criterion, self.device</span><br><span class="line">        )</span><br><span class="line">        <span class="comment">#记录并返回模型：使用self.logger记录训练前后的损失和准确率变化。然后，使用SerializationTool.serialize_model方法将训练后的模型序列化为某种格式，并返回该序列化模型。</span></span><br><span class="line">        self.logger.log(</span><br><span class="line">            <span class="string">&quot;client [&#123;&#125;] [red]loss: &#123;:.4f&#125; -&gt; &#123;:.4f&#125;   [blue]acc: &#123;:.2f&#125;% -&gt; &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                self.<span class="built_in">id</span>,</span><br><span class="line">                loss_before,</span><br><span class="line">                loss_after,</span><br><span class="line">                acc_before * <span class="number">100.0</span>,</span><br><span class="line">                acc_after * <span class="number">100.0</span>,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> SerializationTool.serialize_model(self.model)</span><br></pre></td></tr></table></figure>
<h5 id="函数：-train">函数：_train()</h5>
<p>作用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_train</span>(<span class="params">self, hessian_free=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment">#使用Hessian-free方法的Per-FedAvg（HF）</span></span><br><span class="line">    <span class="comment">#当hessian_free为True时，该方法将执行Hessian-free的Per-FedAvg训练过程。这通常涉及计算二阶导数（Hessian）的近似，以优化模型参数。</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="keyword">if</span> hessian_free:  <span class="comment"># Per-FedAvg(HF)</span></span><br><span class="line">        <span class="comment">#对于每个本地训练周期（self.local_epochs），首先复制当前模型（self.model）到一个临时模型（temp_model）中。</span></span><br><span class="line">        <span class="comment">#使用get_data_batch方法获取第一批数据（data_batch_1），并计算关于临时模型的一阶梯度（grads）。</span></span><br><span class="line">        <span class="comment">#使用这些梯度来更新临时模型的参数（这里使用了简单的SGD更新，但学习率self.alpha可能需要根据实际情况调整）。</span></span><br><span class="line">        <span class="comment">#接着，获取第二批数据（data_batch_2），并再次计算关于临时模型的一阶梯度（grads_1st）。</span></span><br><span class="line">        <span class="comment">#然后，获取第三批数据（data_batch_3），但这次计算的是关于原始模型（self.model）的二阶梯度（Hessian向量积，即grads_2nd）。注意，这里的计算可能需要特定的函数或库，因为直接计算完整的Hessian矩阵是计算密集且不可行的。</span></span><br><span class="line">        <span class="comment">#最后，使用这些一阶梯度和二阶梯度来更新原始模型的参数。更新规则似乎结合了梯度下降和二阶优化方法（具体是哪种方法取决于self.beta和self.alpha的值）。</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.local_epochs):</span><br><span class="line">            temp_model = deepcopy(self.model)</span><br><span class="line">            data_batch_1 = self.get_data_batch()</span><br><span class="line">            grads = self.compute_grad(temp_model, data_batch_1)</span><br><span class="line">            <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>(temp_model.parameters(), grads):</span><br><span class="line">                param.data.sub_(self.alpha * grad)</span><br><span class="line"></span><br><span class="line">            data_batch_2 = self.get_data_batch()</span><br><span class="line">            grads_1st = self.compute_grad(temp_model, data_batch_2)</span><br><span class="line"></span><br><span class="line">            data_batch_3 = self.get_data_batch()</span><br><span class="line"></span><br><span class="line">            grads_2nd = self.compute_grad(</span><br><span class="line">                self.model, data_batch_3, v=grads_1st, second_order_grads=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># <span class="doctag">NOTE:</span> Go check https://github.com/KarhouTam/Per-FedAvg/issues/2 if you confuse about the model update.</span></span><br><span class="line">            <span class="keyword">for</span> param, grad1, grad2 <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                self.model.parameters(), grads_1st, grads_2nd</span><br><span class="line">            ):</span><br><span class="line">                param.data.sub_(self.beta * grad1 - self.beta * self.alpha * grad2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># Per-FedAvg(FO）</span></span><br><span class="line">        	<span class="comment">#只使用一阶梯度的Per-FedAvg（FO）</span></span><br><span class="line">            <span class="comment">#首先在一个临时模型（temp_model）上计算第一个数据批次（data_batch_1）的梯度，并更新临时模型的参数。</span></span><br><span class="line">            <span class="comment">#然后，它获取第二个数据批次（data_batch_2）并计算梯度，但这次它直接在原始模型（self.model）上应用这些梯度的更新，而不是临时模型。</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.local_epochs):</span><br><span class="line">            <span class="comment"># ========================== FedAvg ==========================</span></span><br><span class="line">            <span class="comment"># <span class="doctag">NOTE:</span> You can uncomment those codes for running FedAvg.</span></span><br><span class="line">            <span class="comment">#       When you&#x27;re trying to run FedAvg, comment other codes in this branch.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># data_batch = self.get_data_batch()</span></span><br><span class="line">            <span class="comment"># grads = self.compute_grad(self.model, data_batch)</span></span><br><span class="line">            <span class="comment"># for param, grad in zip(self.model.parameters(), grads):</span></span><br><span class="line">            <span class="comment">#     param.data.sub_(self.beta * grad)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ============================================================</span></span><br><span class="line"></span><br><span class="line">            temp_model = deepcopy(self.model)</span><br><span class="line">            data_batch_1 = self.get_data_batch()</span><br><span class="line">            grads = self.compute_grad(temp_model, data_batch_1)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>(temp_model.parameters(), grads):</span><br><span class="line">                param.data.sub_(self.alpha * grad)</span><br><span class="line"></span><br><span class="line">            data_batch_2 = self.get_data_batch()</span><br><span class="line">            grads = self.compute_grad(temp_model, data_batch_2)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>(self.model.parameters(), grads):</span><br><span class="line">                param.data.sub_(self.beta * grad)</span><br></pre></td></tr></table></figure>
<h5 id="函数：compute-grad">函数：compute_grad()</h5>
<p>作用：根据给定的数据批次<code>data_batch</code>计算模型<code>model</code>的梯度。如果<code>second_order_grads</code>为<code>True</code>，它将计算二阶梯度（Hessian-vector积的一个近似），否则，它将计算标准的一阶梯度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_grad</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    model: torch.nn.Module,</span></span><br><span class="line"><span class="params">    data_batch: <span class="type">Tuple</span>[torch.Tensor, torch.Tensor],</span></span><br><span class="line"><span class="params">    v: <span class="type">Union</span>[<span class="type">Tuple</span>[torch.Tensor, ...], <span class="literal">None</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    second_order_grads=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    x, y = data_batch</span><br><span class="line">    <span class="keyword">if</span> second_order_grads:</span><br><span class="line">        frz_model_params = deepcopy(model.state_dict())</span><br><span class="line">        delta = <span class="number">1e-3</span></span><br><span class="line">        dummy_model_params_1 = OrderedDict()</span><br><span class="line">        dummy_model_params_2 = OrderedDict()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> (layer_name, param), grad <span class="keyword">in</span> <span class="built_in">zip</span>(model.named_parameters(), v):</span><br><span class="line">                dummy_model_params_1.update(&#123;layer_name: param + delta * grad&#125;)</span><br><span class="line">                dummy_model_params_2.update(&#123;layer_name: param - delta * grad&#125;)</span><br><span class="line"></span><br><span class="line">        model.load_state_dict(dummy_model_params_1, strict=<span class="literal">False</span>)</span><br><span class="line">        logit_1 = model(x)</span><br><span class="line">        loss_1 = self.criterion(logit_1, y)</span><br><span class="line">        grads_1 = torch.autograd.grad(loss_1, model.parameters())</span><br><span class="line"></span><br><span class="line">        model.load_state_dict(dummy_model_params_2, strict=<span class="literal">False</span>)</span><br><span class="line">        logit_2 = model(x)</span><br><span class="line">        loss_2 = self.criterion(logit_2, y)</span><br><span class="line">        grads_2 = torch.autograd.grad(loss_2, model.parameters())</span><br><span class="line"></span><br><span class="line">        model.load_state_dict(frz_model_params)</span><br><span class="line"></span><br><span class="line">        grads = []</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> g1, g2 <span class="keyword">in</span> <span class="built_in">zip</span>(grads_1, grads_2):</span><br><span class="line">                grads.append((g1 - g2) / (<span class="number">2</span> * delta))</span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logit = model(x)</span><br><span class="line">        loss = self.criterion(logit, y)</span><br><span class="line">        grads = torch.autograd.grad(loss, model.parameters())</span><br><span class="line">        <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure>
<h5 id="函数：pers-N-eval">函数：pers_N_eval()</h5>
<p>作用：在给定全局模型（<code>global_model</code>）和个性化训练轮次（<code>pers_epochs</code>）之后，该函数首先加载全局模型的参数到客户端的本地模型（<code>self.model</code>），然后在本地数据集上进行训练和评估。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pers_N_eval</span>(<span class="params">self, global_model: torch.nn.Module, pers_epochs: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="comment">#加载全局模型参数：</span></span><br><span class="line">    self.model.load_state_dict(global_model.state_dict())</span><br><span class="line">	</span><br><span class="line">    <span class="comment">#评估初始模型性能：</span></span><br><span class="line">    loss_before, acc_before = utils.<span class="built_in">eval</span>(</span><br><span class="line">        self.model, self.valloader, self.criterion, self.device</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#定义优化器：</span></span><br><span class="line">    optimizer = torch.optim.SGD(self.model.parameters(), lr=self.alpha)</span><br><span class="line">    <span class="comment">#个性化训练：这部分代码执行了 pers_epochs 轮次的个性化训练。在每次迭代中，它首先从 self.get_data_batch() 获取一个数据批次，然后使用这个数据批次来更新模型的参数。</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(pers_epochs):</span><br><span class="line">        x, y = self.get_data_batch()</span><br><span class="line">        logit = self.model(x)</span><br><span class="line">        loss = self.criterion(logit, y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">     <span class="comment">#评估训练后的模型性能：在个性化训练完成后，再次评估模型的性能。</span></span><br><span class="line">    loss_after, acc_after = utils.<span class="built_in">eval</span>(</span><br><span class="line">        self.model, self.valloader, self.criterion, self.device</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#记录并输出日志：使用日志记录器（self.logger）来记录训练前后的损失和准确率。这里还使用了颜色代码（如 [red] 和 [blue]），但这些可能不会在纯文本日志中显示，除非日志记录器进</span></span><br><span class="line">    self.logger.log(</span><br><span class="line">        <span class="string">&quot;client [&#123;&#125;] [red]loss: &#123;:.4f&#125; -&gt; &#123;:.4f&#125;   [blue]acc: &#123;:.2f&#125;% -&gt; &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">            self.<span class="built_in">id</span>, loss_before, loss_after, acc_before * <span class="number">100.0</span>, acc_after * <span class="number">100.0</span></span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#返回评估结果：</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;loss_before&quot;</span>: loss_before,</span><br><span class="line">        <span class="string">&quot;acc_before&quot;</span>: acc_before,</span><br><span class="line">        <span class="string">&quot;loss_after&quot;</span>: loss_after,</span><br><span class="line">        <span class="string">&quot;acc_after&quot;</span>: acc_after,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="main-py"><a href="http://main.py">main.py</a></h4>
<p>用于启动分布式或联邦学习中的客户端或服务器进程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    </span><br><span class="line">    args = get_args()<span class="comment">#使用get_args()从命令行获取参数，并将这些参数存储在一个对象中</span></span><br><span class="line">    fix_random_seed(args.seed)<span class="comment">#用于设置随机种子，确保实验的可重复性。</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(<span class="string">&quot;./log&quot;</span>) == <span class="literal">False</span>:<span class="comment">#这行代码检查当前目录下是否存在一个名为log的目录。如果不存在，则执行下一行代码。</span></span><br><span class="line">        os.mkdir(<span class="string">&quot;./log&quot;</span>)<span class="comment">#如果log目录不存在，这行代码会创建它。os.mkdir用于创建新目录。</span></span><br><span class="line">    <span class="comment">#首先，检查args对象中是否有gpu参数且其值为True；其次，检查是否有可用的CUDA设备（即是否有NVIDIA GPU并安装了适当的CUDA和PyTorch版本）。</span></span><br><span class="line">    <span class="keyword">if</span> args.gpu <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">        device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">     </span><br><span class="line">    global_model = get_model(args.dataset, device)<span class="comment">#创建了一个日志记录器对象logger</span></span><br><span class="line">    logger = Console(record=args.log)</span><br><span class="line">    logger.log(<span class="string">f&quot;Arguments:&quot;</span>, <span class="built_in">dict</span>(args._get_kwargs()))</span><br><span class="line">    clients_4_training, clients_4_eval, client_num_in_total = get_client_id_indices(</span><br><span class="line">        args.dataset</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># init clients </span></span><br><span class="line">    <span class="comment">#初始化一个客户端列表，每个客户端都是PerFedAvgClient类的实例。</span></span><br><span class="line">    clients = [</span><br><span class="line">        PerFedAvgClient(</span><br><span class="line">            client_id=client_id,</span><br><span class="line">            alpha=args.alpha,</span><br><span class="line">            beta=args.beta,</span><br><span class="line">            global_model=global_model,</span><br><span class="line">            criterion=torch.nn.CrossEntropyLoss(),</span><br><span class="line">            batch_size=args.batch_size,</span><br><span class="line">            dataset=args.dataset,</span><br><span class="line">            local_epochs=args.local_epochs,</span><br><span class="line">            valset_ratio=args.valset_ratio,</span><br><span class="line">            logger=logger,</span><br><span class="line">            gpu=args.gpu,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> client_id <span class="keyword">in</span> <span class="built_in">range</span>(client_num_in_total)</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    <span class="comment">#开始训练过程的，并且它使用了日志记录器（logger）来输出到log。</span></span><br><span class="line">    logger.log(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>, <span class="string">&quot;TRAINING&quot;</span>, <span class="string">&quot;=&quot;</span> * <span class="number">20</span>, style=<span class="string">&quot;bold red&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> track(			<span class="comment">#全局训练循环:</span></span><br><span class="line">        <span class="built_in">range</span>(args.global_epochs), <span class="string">&quot;Training...&quot;</span>, console=logger, disable=args.log</span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># select clients   </span></span><br><span class="line">        <span class="comment">#选择客户端:在每次全局迭代中，代码从clients_4_training中随机选择args.client_num_per_round个客户端进行本地训练。</span></span><br><span class="line">        selected_clients = random.sample(clients_4_training, args.client_num_per_round)</span><br><span class="line"></span><br><span class="line">        model_params_cache = []</span><br><span class="line">        <span class="comment"># client local training 客户端本地训练</span></span><br><span class="line">        <span class="comment">#对于选定的每个客户端，代码执行train方法。该方法以当前的全局模型作为起点，并可能在本地数据集上进行训练。train方法返回序列化后的模型参数，这些参数被添加到model_params_cache列表中。</span></span><br><span class="line">        <span class="keyword">for</span> client_id <span class="keyword">in</span> selected_clients:</span><br><span class="line">            serialized_model_params = clients[client_id].train(</span><br><span class="line">                global_model=global_model,</span><br><span class="line">                hessian_free=args.hf,</span><br><span class="line">                eval_while_training=args.eval_while_training,</span><br><span class="line">            )</span><br><span class="line">            model_params_cache.append(serialized_model_params)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># aggregate model parameters聚合模型参数:</span></span><br><span class="line">        <span class="comment">#在所有选定的客户端完成本地训练后，代码使用fedavg_aggregate函数（来聚合模型参数。这个函数将model_params_cache列表中的模型参数进行聚合（通常使用FedAvg算法，即加权平均）。然后，使用deserialize_model函数将聚合后的模型参数反序列化并应用到global_model上，从而更新全局模型。</span></span><br><span class="line">        aggregated_model_params = Aggregators.fedavg_aggregate(model_params_cache)</span><br><span class="line">        SerializationTool.deserialize_model(global_model, aggregated_model_params)</span><br><span class="line">        <span class="comment">#分隔符日志:</span></span><br><span class="line">        <span class="comment">#最后，代码使用logger对象输出一个由60个等号字符组成的分隔符，可能用于在日志中分隔不同的全局迭代轮次</span></span><br><span class="line">        logger.log(<span class="string">&quot;=&quot;</span> * <span class="number">60</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#描述了联邦学习中的评估过程，并且它记录了模型在评估前后的性能。</span></span><br><span class="line">    <span class="comment"># eval</span></span><br><span class="line">    pers_epochs = args.local_epochs <span class="keyword">if</span> args.pers_epochs == -<span class="number">1</span> <span class="keyword">else</span> args.pers_epochs <span class="comment">#确定持久化轮次（Persistent Epochs）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#开始评估日志</span></span><br><span class="line">    <span class="comment">#初始化评估结果列表</span></span><br><span class="line">    <span class="comment">#这四个列表用于存储每个客户端在评估前后的损失和准确率。</span></span><br><span class="line">    logger.log(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>, <span class="string">&quot;EVALUATION&quot;</span>, <span class="string">&quot;=&quot;</span> * <span class="number">20</span>, style=<span class="string">&quot;bold blue&quot;</span>)</span><br><span class="line">    loss_before = []</span><br><span class="line">    loss_after = []</span><br><span class="line">    acc_before = []</span><br><span class="line">    acc_after = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#客户端评估循环</span></span><br><span class="line">    <span class="comment">#代码遍历clients_4_eval列表中的每个客户端ID，并对每个客户端执行pers_N_eval方法。这个方法在评估前对模型进行本地训练（使用pers_epochs指定的轮次），然后评估模型的性能，并返回一个包含损失和准确率的字典。这些值随后被添加到相应的列表中。</span></span><br><span class="line">    <span class="keyword">for</span> client_id <span class="keyword">in</span> track(</span><br><span class="line">        clients_4_eval, <span class="string">&quot;Evaluating...&quot;</span>, console=logger, disable=args.log</span><br><span class="line">    ):</span><br><span class="line">        stats = clients[client_id].pers_N_eval(</span><br><span class="line">            global_model=global_model, pers_epochs=pers_epochs,</span><br><span class="line">        )</span><br><span class="line">        loss_before.append(stats[<span class="string">&quot;loss_before&quot;</span>])</span><br><span class="line">        loss_after.append(stats[<span class="string">&quot;loss_after&quot;</span>])</span><br><span class="line">        acc_before.append(stats[<span class="string">&quot;acc_before&quot;</span>])</span><br><span class="line">        acc_after.append(stats[<span class="string">&quot;acc_after&quot;</span>])</span><br><span class="line">	</span><br><span class="line">    <span class="comment">#输出评估结果</span></span><br><span class="line">    <span class="comment">#代码使用logger对象输出评估结果。它计算了所有客户端的平均损失和准确率，并将它们以格式化的方式输出。</span></span><br><span class="line">    logger.log(<span class="string">&quot;=&quot;</span> * <span class="number">20</span>, <span class="string">&quot;RESULTS&quot;</span>, <span class="string">&quot;=&quot;</span> * <span class="number">20</span>, style=<span class="string">&quot;bold green&quot;</span>)</span><br><span class="line">    logger.log(<span class="string">f&quot;loss_before_pers: <span class="subst">&#123;(<span class="built_in">sum</span>(loss_before) / <span class="built_in">len</span>(loss_before)):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    logger.log(<span class="string">f&quot;acc_before_pers: <span class="subst">&#123;(<span class="built_in">sum</span>(acc_before) * <span class="number">100.0</span> / <span class="built_in">len</span>(acc_before)):<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    logger.log(<span class="string">f&quot;loss_after_pers: <span class="subst">&#123;(<span class="built_in">sum</span>(loss_after) / <span class="built_in">len</span>(loss_after)):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    logger.log(<span class="string">f&quot;acc_after_pers: <span class="subst">&#123;(<span class="built_in">sum</span>(acc_after) * <span class="number">100.0</span> / <span class="built_in">len</span>(acc_after)):<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存评估结果（如果启用日志）</span></span><br><span class="line">    <span class="keyword">if</span> args.log:</span><br><span class="line">        algo = <span class="string">&quot;HF&quot;</span> <span class="keyword">if</span> args.hf <span class="keyword">else</span> <span class="string">&quot;FO&quot;</span></span><br><span class="line">        logger.save_html(</span><br><span class="line">            <span class="string">f&quot;./log/<span class="subst">&#123;args.dataset&#125;</span>_<span class="subst">&#123;args.client_num_per_round&#125;</span>_<span class="subst">&#123;args.global_epochs&#125;</span>_<span class="subst">&#123;pers_epochs&#125;</span>_<span class="subst">&#123;algo&#125;</span>.html&quot;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="Per-FeAVG源码分析——data目录下：">Per_FeAVG源码分析——data目录下：</h3>
<h4 id="init-py"><a href="http://init.py">init.py</a></h4>
<p>不做分析</p>
<h4 id="utils-py-2"><a href="http://utils.py">utils.py</a></h4>
<h5 id="字典：DATASET-DICT">字典：DATASET_DICT</h5>
<p>作用：它将字符串键（如 <code>&quot;mnist&quot;</code> 和 <code>&quot;cifar&quot;</code>）映射到对应的类（<code>MNISTDataset</code> 和 <code>CIFARDataset</code>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DATASET_DICT = &#123;</span><br><span class="line">    <span class="string">&quot;mnist&quot;</span>: MNISTDataset,</span><br><span class="line">    <span class="string">&quot;cifar&quot;</span>: CIFARDataset,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="函数：CURRENT-DIR">函数：CURRENT_DIR</h5>
<p>作用：<code>CURRENT_DIR</code> 被设置为当前 Python 脚本文件的父目录的绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CURRENT_DIR = Path(__file__).parent.abspath()</span><br></pre></td></tr></table></figure>
<h5 id="函数：get-dataloader">函数：get_dataloader</h5>
<p>作用：从一个预处理好的 pickle 文件中加载数据集，并根据给定的 <code>client_id</code> 分割为训练集和验证集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataloader</span>(<span class="params">dataset: <span class="built_in">str</span>, client_id: <span class="built_in">int</span>, batch_size=<span class="number">20</span>, valset_ratio=<span class="number">0.1</span></span>):</span><br><span class="line">    pickles_dir = CURRENT_DIR / dataset / <span class="string">&quot;pickles&quot;</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(pickles_dir) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Please preprocess and create pickles first.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(pickles_dir / <span class="built_in">str</span>(client_id) + <span class="string">&quot;.pkl&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        client_dataset: DATASET_DICT[dataset] = pickle.load(f)</span><br><span class="line"></span><br><span class="line">    val_num_samples = <span class="built_in">int</span>(valset_ratio * <span class="built_in">len</span>(client_dataset))</span><br><span class="line">    train_num_samples = <span class="built_in">len</span>(client_dataset) - val_num_samples</span><br><span class="line"></span><br><span class="line">    trainset, valset = random_split(</span><br><span class="line">        client_dataset, [train_num_samples, val_num_samples]</span><br><span class="line">    )</span><br><span class="line">    trainloader = DataLoader(trainset, batch_size, drop_last=<span class="literal">True</span>)</span><br><span class="line">    valloader = DataLoader(valset, batch_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> trainloader, valloader</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="函数：get-client-id-indices-dataset">函数：get_client_id_indices(dataset)</h5>
<p>作用：从一个特定的 pickle 文件中加载并返回关于数据集分割的信息。从一个 <code>seperation.pkl</code> 文件中读取训练集、测试集以及总数目的索引或标识符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_client_id_indices</span>(<span class="params">dataset</span>):</span><br><span class="line">    dataset_pickles_path = CURRENT_DIR / dataset / <span class="string">&quot;pickles&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_pickles_path / <span class="string">&quot;seperation.pkl&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        seperation = pickle.load(f)</span><br><span class="line">    <span class="keyword">return</span> (seperation[<span class="string">&quot;train&quot;</span>], seperation[<span class="string">&quot;test&quot;</span>], seperation[<span class="string">&quot;total&quot;</span>])</span><br></pre></td></tr></table></figure>
<h4 id="preprocess-py"><a href="http://preprocess.py">preprocess.py</a></h4>
<h5 id="函数：CURRENT-DIR-2">函数：CURRENT_DIR</h5>
<p>作用：<code>CURRENT_DIR</code> 被设置为当前 Python 脚本文件的父目录的绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CURRENT_DIR = Path(__file__).parent.abspath()</span><br></pre></td></tr></table></figure>
<h5 id="字典：DATASET">字典：DATASET</h5>
<p>作用：数据集名称映射到了两个元组，可以基于数据集名称来动态地加载和实例化相应的数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DATASET = &#123;</span><br><span class="line">    <span class="string">&quot;mnist&quot;</span>: (MNIST, MNISTDataset),</span><br><span class="line">    <span class="string">&quot;cifar&quot;</span>: (CIFAR10, CIFARDataset),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="字典：MEAN">字典：MEAN</h5>
<p>作用：用来存储不同数据集的像素均值。这些均值通常用于数据归一化，只包含一个灰度通道，因此其均值是一个单元素元组 <code>(0.1307,)</code>。这意味着当你对 MNIST 数据集进行归一化时，你会从每个像素值中减去 0.1307。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MEAN = &#123;</span><br><span class="line">    <span class="string">&quot;mnist&quot;</span>: (<span class="number">0.1307</span>,),</span><br><span class="line">    <span class="string">&quot;cifar&quot;</span>: (<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="字典：STD">字典：STD</h5>
<p>作用：存储不同数据集的像素标准差。使用归一化时，标准差通常与均值一起使用，以确保数据的每个特征（在这个案例中是像素值）都有相似的尺度。它只包含一个灰度通道，因此其标准差是一个单元素元组 <code>(0.3015,)</code>。这意味着在归一化 MNIST 数据时，每个像素值都会根据其灰度通道的标准差进行缩放。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">STD = &#123;</span><br><span class="line">    <span class="string">&quot;mnist&quot;</span>: (<span class="number">0.3015</span>,),</span><br><span class="line">    <span class="string">&quot;cifar&quot;</span>: (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="函数：preprocess">函数：preprocess()</h5>
<p>作用：用于预处理数据集，在联邦学习或分布式学习的场景中，数据需要在多个客户端（或节点）之间分配。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">args: Namespace</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="comment">#参数和目录设置：</span></span><br><span class="line">    <span class="comment">#设置数据集目录（dataset_dir）和pickle文件目录（pickles_dir）。</span></span><br><span class="line">    dataset_dir = CURRENT_DIR / args.dataset</span><br><span class="line">    pickles_dir = CURRENT_DIR / args.dataset / <span class="string">&quot;pickles&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#设置随机数生成器的种子，以确保结果的可重复性。</span></span><br><span class="line">    np.random.seed(args.seed)</span><br><span class="line">    random.seed(args.seed)</span><br><span class="line">    torch.manual_seed(args.seed)</span><br><span class="line">    num_train_clients = <span class="built_in">int</span>(args.client_num_in_total * args.fraction)</span><br><span class="line">    num_test_clients = args.client_num_in_total - num_train_clients</span><br><span class="line"></span><br><span class="line">    <span class="comment">#数据转换</span></span><br><span class="line">    <span class="comment">#定义了一个转换transform，它只包含标准化（假设MEAN和STD是预定义的字典，包含了每个数据集的均值和标准差），初始化了训练集和测试集的统计信息字典</span></span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [transforms.Normalize(MEAN[args.dataset], STD[args.dataset]),]</span><br><span class="line">    )</span><br><span class="line">    target_transform = <span class="literal">None</span></span><br><span class="line">    trainset_stats = &#123;&#125;</span><br><span class="line">    testset_stats = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#目录和文件处理：</span></span><br><span class="line">    <span class="comment">#检查数据集目录是否存在，如果不存在则创建它。</span></span><br><span class="line">    <span class="comment">#如果pickle目录已经存在，则删除它（可能是为了确保没有旧的pickle文件干扰）。</span></span><br><span class="line">    <span class="comment">#创建新的pickle目录。</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(CURRENT_DIR / args.dataset):</span><br><span class="line">        os.mkdir(CURRENT_DIR / args.dataset)</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(pickles_dir):</span><br><span class="line">        os.system(<span class="string">f&quot;rm -rf <span class="subst">&#123;pickles_dir&#125;</span>&quot;</span>)</span><br><span class="line">    os.mkdir(<span class="string">f&quot;<span class="subst">&#123;pickles_dir&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#加载数据集</span></span><br><span class="line">    <span class="comment">#从预定义的DATASET字典中获取原始和目标数据集。</span></span><br><span class="line">    <span class="comment">#使用ori_dataset类创建训练集和测试集。注意，训练集在加载时还指定了download=True（用于自动下载数据集），而测试集没有。两者都使用了transforms.ToTensor()进行初步的数据转换。</span></span><br><span class="line">    ori_dataset, target_dataset = DATASET[args.dataset]</span><br><span class="line">    trainset = ori_dataset(</span><br><span class="line">        dataset_dir, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transforms.ToTensor()</span><br><span class="line">    )</span><br><span class="line">    testset = ori_dataset(dataset_dir, train=<span class="literal">False</span>, transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#分配类别到客户端</span></span><br><span class="line">    <span class="comment">#根据args.classes确定每个客户端应有的类别数量（默认为10类）</span></span><br><span class="line">    <span class="comment">#使用randomly_alloc_classes函数将类别随机分配给训练集和测试集的客户端</span></span><br><span class="line">    <span class="comment">#randomly_alloc_classes函数还返回每个子集的统计信息（</span></span><br><span class="line">    num_classes = <span class="number">10</span> <span class="keyword">if</span> args.classes &lt;= <span class="number">0</span> <span class="keyword">else</span> args.classes</span><br><span class="line">    all_trainsets, trainset_stats = randomly_alloc_classes(</span><br><span class="line">        ori_dataset=trainset,</span><br><span class="line">        target_dataset=target_dataset,</span><br><span class="line">        num_clients=num_train_clients,</span><br><span class="line">        num_classes=num_classes,</span><br><span class="line">        transform=transform,</span><br><span class="line">        target_transform=target_transform,</span><br><span class="line">    )</span><br><span class="line">    all_testsets, testset_stats = randomly_alloc_classes(</span><br><span class="line">        ori_dataset=testset,</span><br><span class="line">        target_dataset=target_dataset,</span><br><span class="line">        num_clients=num_test_clients,</span><br><span class="line">        num_classes=num_classes,</span><br><span class="line">        transform=transform,</span><br><span class="line">        target_transform=target_transform,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将所有训练集和测试集组合到一个列表all_datasets中</span></span><br><span class="line">    all_datasets = all_trainsets + all_testsets</span><br><span class="line"></span><br><span class="line">    <span class="comment">#保存客户端数据集为pickle文件</span></span><br><span class="line">    <span class="comment">#通过enumerate(all_datasets)遍历all_datasets列表中的每个数据集和对应的client_id（即客户端的ID）。</span></span><br><span class="line">    <span class="comment">#使用pathlib的/操作符（如果pickles_dir是pathlib.Path对象）来构建pickle文件的路径。</span></span><br><span class="line">    <span class="comment">#使用pickle.dump()函数将每个数据集保存到对应的pickle文件中。</span></span><br><span class="line">    <span class="keyword">for</span> client_id, dataset <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_datasets):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(pickles_dir / <span class="built_in">str</span>(client_id) + <span class="string">&quot;.pkl&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            pickle.dump(dataset, f)</span><br><span class="line">     </span><br><span class="line">    <span class="comment">#保存客户端索引</span></span><br><span class="line">    <span class="comment">#创建一个字典，其中包含三个键：“train”、“test”和“total”，“total”的值就是总的客户端数量。</span></span><br><span class="line">    <span class="comment">#“train”和“test”的值是客户端ID的列表，分别代表训练集和测试集的客户端。这里假设num_train_clients表示训练集客户端的数量，而args.client_num_in_total表示总的客户端数量。</span></span><br><span class="line">    <span class="comment">#使用pickle.dump()函数将这个字典保存到名为“seperation.pkl”的文件中。这个文件用于在后续的训练和测试过程中区分哪些客户端是训练集，哪些是测试集</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(pickles_dir / <span class="string">&quot;seperation.pkl&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;train&quot;</span>: [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train_clients)],</span><br><span class="line">                <span class="string">&quot;test&quot;</span>: [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_train_clients, args.client_num_in_total)],</span><br><span class="line">                <span class="string">&quot;total&quot;</span>: args.client_num_in_total,</span><br><span class="line">            &#125;,</span><br><span class="line">            f,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#保存数据集统计信息</span></span><br><span class="line">    <span class="comment">#trainset_stats和testset_stats是在之前的预处理步骤中收集的训练集和测试集的统计信息。</span></span><br><span class="line">    <span class="comment">#使用json.dump()函数将这些统计信息保存为JSON格式的文件“all_stats.json”。这个文件用于在后续的模型训练和评估过程中提供数据集的相关信息</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_dir / <span class="string">&quot;all_stats.json&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(&#123;<span class="string">&quot;train&quot;</span>: trainset_stats, <span class="string">&quot;test&quot;</span>: testset_stats&#125;, f)</span><br></pre></td></tr></table></figure>
<h5 id="函数：randomly-alloc-classes">函数：randomly_alloc_classes</h5>
<p>作用：将原始数据集（<code>ori_dataset</code>）中的样本随机分配给多个客户端（或用户），同时确保每个客户端获得指定数量的不同类别的样本。函数还返回了分配给每个客户端的数据集列表和相应的统计信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">randomly_alloc_classes</span>(<span class="params"></span></span><br><span class="line"><span class="params">    ori_dataset: Dataset,</span></span><br><span class="line"><span class="params">    target_dataset: Dataset,</span></span><br><span class="line"><span class="params">    num_clients: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    num_classes: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    target_transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>[Dataset], <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">int</span>]]]:</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#分配样本</span></span><br><span class="line">    <span class="comment">#使用noniid_slicing函数来将ori_dataset中的样本分配给num_clients个客户端。这个函数应该返回一个字典，其中键是客户端ID，值是分配给该客户端的样本索引列表。</span></span><br><span class="line">    dict_users = noniid_slicing(ori_dataset, num_clients, num_clients * num_classes)</span><br><span class="line">    stats = &#123;&#125;</span><br><span class="line">    <span class="comment">#收集统计信息</span></span><br><span class="line">    <span class="comment">#对于每个客户端，从ori_dataset中提取标签（ori_dataset.targets），然后根据分配给该客户端的样本索引列表计算标签的类别分布。这些统计信息被存储在stats字典中。</span></span><br><span class="line">    <span class="keyword">for</span> i, indices <span class="keyword">in</span> dict_users.items():</span><br><span class="line">        targets_numpy = np.array(ori_dataset.targets)</span><br><span class="line">        stats[<span class="string">f&quot;client <span class="subst">&#123;i&#125;</span>&quot;</span>] = &#123;<span class="string">&quot;x&quot;</span>: <span class="number">0</span>, <span class="string">&quot;y&quot;</span>: &#123;&#125;&#125;</span><br><span class="line">        stats[<span class="string">f&quot;client <span class="subst">&#123;i&#125;</span>&quot;</span>][<span class="string">&quot;x&quot;</span>] = <span class="built_in">len</span>(indices)</span><br><span class="line">        stats[<span class="string">f&quot;client <span class="subst">&#123;i&#125;</span>&quot;</span>][<span class="string">&quot;y&quot;</span>] = Counter(targets_numpy[indices].tolist())</span><br><span class="line">    datasets = []</span><br><span class="line">    <span class="comment">#创建数据集</span></span><br><span class="line">    <span class="comment">#使用target_dataset类从ori_dataset中创建子集，每个子集对应于一个客户端。这是通过从ori_dataset中提取分配给该客户端的样本，并传递给target_dataset的构造函数来实现的。</span></span><br><span class="line">    <span class="keyword">for</span> indices <span class="keyword">in</span> dict_users.values():</span><br><span class="line">        datasets.append(</span><br><span class="line">            target_dataset(</span><br><span class="line">                [ori_dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices],</span><br><span class="line">                transform=transform,</span><br><span class="line">                target_transform=target_transform,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> datasets, stats</span><br></pre></td></tr></table></figure>
<h5 id="函数：-name-“main”">函数：__name__==“main”</h5>
<p>作用：基本的命令行参数解析设置，它使用<code>argparse</code>库来从命令行获取参数。这些参数包括数据集类型、客户端总数、训练客户端的比例、每个客户端数据所属的类别数量以及随机种子。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = ArgumentParser()</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, choices=[<span class="string">&quot;mnist&quot;</span>, <span class="string">&quot;cifar&quot;</span>], default=<span class="string">&quot;mnist&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--client_num_in_total&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">200</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--fraction&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.9</span>, <span class="built_in">help</span>=<span class="string">&quot;Propotion of train clients&quot;</span></span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&quot;--classes&quot;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">        default=<span class="number">2</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;Num of classes that one client&#x27;s data belong to.&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--seed&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    preprocess(args)</span><br></pre></td></tr></table></figure>
<h4 id="dataset-py"><a href="http://dataset.py">dataset.py</a></h4>
<h5 id="类：MNISTDataset-Dataset">类：MNISTDataset(Dataset)</h5>
<h6 id="函数：init-2">函数：init</h6>
<p>作用：用于初始化一个对象的状态</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    <span class="comment">#参数</span></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    subset=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    data=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    targets=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    target_transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="comment">#处理</span></span><br><span class="line">    self.transform = transform</span><br><span class="line">    self.target_transform = target_transform</span><br><span class="line">    <span class="comment">#如果data和targets都非空，它将data增加一个新的维度（使用unsqueeze(1)），并将data和targets设置为对象的属性。</span></span><br><span class="line">    <span class="keyword">if</span> (data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (targets <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        self.data = data.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        self.targets = targets</span><br><span class="line">    <span class="comment"># 如果subset非空，它将遍历subset，检查元组中的每个元素是否为张量。如果不是，它将使用torch.tensor将其转换为张量。然后，它使用torch.stack将数据和标签分别堆叠成张量，并设置为对象的属性。   </span></span><br><span class="line">    <span class="keyword">elif</span> subset <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.data = torch.stack(</span><br><span class="line">            <span class="built_in">list</span>(</span><br><span class="line">                <span class="built_in">map</span>(</span><br><span class="line">                    <span class="keyword">lambda</span> tup: tup[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">isinstance</span>(tup[<span class="number">0</span>], torch.Tensor)</span><br><span class="line">                    <span class="keyword">else</span> torch.tensor(tup[<span class="number">0</span>]),</span><br><span class="line">                    subset,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        self.targets = torch.stack(</span><br><span class="line">            <span class="built_in">list</span>(</span><br><span class="line">                <span class="built_in">map</span>(</span><br><span class="line">                    <span class="keyword">lambda</span> tup: tup[<span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">isinstance</span>(tup[<span class="number">1</span>], torch.Tensor)</span><br><span class="line">                    <span class="keyword">else</span> torch.tensor(tup[<span class="number">1</span>]),</span><br><span class="line">                    subset,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    <span class="comment">#如果data和targets以及subset都为空，则抛出一个ValueError，说明需要提供数据格式。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">&quot;Data Format: subset: Tuple(data: Tensor / Image / np.ndarray, targets: Tensor) OR data: List[Tensor]  targets: List[Tensor]&quot;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h6 id="函数：getitem">函数：getitem</h6>
<p>作用：允许类的实例像列表、元组或其他可迭代对象那样进行索引访问。在你提供的上下文中，这个方法通常用于数据加载器（如PyTorch的<code>DataLoader</code>），以便在训练或评估模型时能够按索引访问数据集中的单个样本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">    data, targets = self.data[index], self.targets[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        data = self.transform(self.data[index])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.target_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        targets = self.target_transform(self.targets[index])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data, targets</span><br></pre></td></tr></table></figure>
<h6 id="函数：len">函数：len</h6>
<p>作用：确定self.data的长度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(self.targets)</span><br></pre></td></tr></table></figure>
<h5 id="类：CIFARDataset-Dataset">类：CIFARDataset(Dataset)</h5>
<h6 id="函数：init-3">函数：init</h6>
<p>作用：用于初始化一个对象的状态</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    subset=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    data=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    targets=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    target_transform=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    self.transform = transform</span><br><span class="line">    self.target_transform = target_transform</span><br><span class="line">    <span class="keyword">if</span> (data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (targets <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        self.data = data.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        self.targets = targets</span><br><span class="line">    <span class="keyword">elif</span> subset <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        self.data = torch.stack(</span><br><span class="line">            <span class="built_in">list</span>(</span><br><span class="line">                <span class="built_in">map</span>(</span><br><span class="line">                    <span class="keyword">lambda</span> tup: tup[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">isinstance</span>(tup[<span class="number">0</span>], torch.Tensor)</span><br><span class="line">                    <span class="keyword">else</span> torch.tensor(tup[<span class="number">0</span>]),</span><br><span class="line">                    subset,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        self.targets = torch.stack(</span><br><span class="line">            <span class="built_in">list</span>(</span><br><span class="line">                <span class="built_in">map</span>(</span><br><span class="line">                    <span class="keyword">lambda</span> tup: tup[<span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">isinstance</span>(tup[<span class="number">1</span>], torch.Tensor)</span><br><span class="line">                    <span class="keyword">else</span> torch.tensor(tup[<span class="number">1</span>]),</span><br><span class="line">                    subset,</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">&quot;Data Format: subset: Tuple(data: Tensor / Image / np.ndarray, targets: Tensor) OR data: List[Tensor]  targets: List[Tensor]&quot;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h6 id="函数：getitem-2">函数：getitem</h6>
<p>作用：允许类的实例像列表、元组或其他可迭代对象那样进行索引访问。在你提供的上下文中，这个方法通常用于数据加载器（如PyTorch的<code>DataLoader</code>），以便在训练或评估模型时能够按索引访问数据集中的单个样本。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">    img, targets = self.data[index], self.targets[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        img = self.transform(self.data[index])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.target_transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        targets = self.target_transform(self.targets[index])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img, targets</span><br></pre></td></tr></table></figure>
<h6 id="函数：len-2">函数：len</h6>
<p>作用：返回长度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(self.targets)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Per_FedAVG</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo文章主题头内各个数据的意义</title>
    <url>/2024/06/24/hexo%E6%96%87%E7%AB%A0%E4%B8%BB%E9%A2%98%E5%A4%B4%E9%87%8C%E5%A1%AB%E5%86%99%E7%9A%84%E6%84%8F%E6%80%9D/</url>
    <content><![CDATA[<h3 id="页面编写（page）">页面编写（page）</h3>
<table>
<thead>
<tr>
<th style="text-align:left">写法</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">title</td>
<td style="text-align:left">【必需】页面标题</td>
</tr>
<tr>
<td style="text-align:left">date</td>
<td style="text-align:left">【必需】页面创建日期</td>
</tr>
<tr>
<td style="text-align:left">type</td>
<td style="text-align:left">【必需】标签、分类和友情链接三个页面需要配置</td>
</tr>
</tbody>
</table>
<h3 id="文章编辑（port1）">文章编辑（port1）</h3>
<table>
<thead>
<tr>
<th style="text-align:left">写法</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">title</td>
<td style="text-align:left">【必需】文章标题</td>
</tr>
<tr>
<td style="text-align:left">date</td>
<td style="text-align:left">【必需】文章创建日期</td>
</tr>
<tr>
<td style="text-align:left">tagas</td>
<td style="text-align:left">【可选】文章标签</td>
</tr>
<tr>
<td style="text-align:left">categories</td>
<td style="text-align:left">【可选】文章分类</td>
</tr>
<tr>
<td style="text-align:left">keywords</td>
<td style="text-align:left">【可选】文章关键字</td>
</tr>
<tr>
<td style="text-align:left">description</td>
<td style="text-align:left">【可选】文章描述</td>
</tr>
<tr>
<td style="text-align:left">cover</td>
<td style="text-align:left">【可选】文章图标</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客编写</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo 命令使用</title>
    <url>/2024/06/23/hexo_%E5%91%BD%E4%BB%A4%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>这个是官网（可以查看主题以及更新）：<a href="https://hexo.io/">Hexo</a><br>
这篇文章是hexo第一篇文章. 点击 <a href="https://hexo.io/docs/">documentation</a> 可以获得更多信息.<br>
可以在 <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> 找到绝大部分hexo相关问题，或者直接去 <a href="https://github.com/hexojs/hexo/issues">GitHub</a>评论留言.</p>
<h2 id="快速开始">快速开始</h2>
<h3 id="创建一个新的文章，文章默认在source-ports-目录下面">创建一个新的文章，文章默认在source/ _ports /目录下面</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>相关: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="在本地上启动">在本地上启动</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>相关: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="生成静态文件">生成静态文件</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>相关: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="部署到网站">部署到网站</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>相关: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>markdown简易上手</title>
    <url>/2024/06/23/markdown%E7%AE%80%E6%98%93%E4%B8%8A%E6%89%8B/</url>
    <content><![CDATA[<h1>markdown简易上手</h1>
<h3 id="编写渠道">编写渠道</h3>
<ul>
<li>软件：收费：<a href="https://typora.ymzhxing.cn/index.html?bd_vid=12314572084174744930%22%E4%B8%AD%E6%96%87%E7%BD%91%E7%AB%99%22">Typora</a>  不收费：<a href="https://apps.microsoft.com/detail/xp9khm4bk9fz7q?launch=true&amp;mode=full&amp;hl=zh-cn&amp;gl=cn&amp;ocid=bingwebsearch%22%E5%AE%98%E7%BD%91%22">VS Code</a>。</li>
<li>网站：程序员聚集网站都有这个功能如<a href="https://www.csdn.net/">CSDN</a>、<a href="https://github.com/">Github</a>。</li>
</ul>
<h3 id="VS-studio配置编辑器的链接">VS studio配置编辑器的链接</h3>
<ul>
<li>这告诉你怎么增加一个Markdown的扩展：<a href="https://blog.csdn.net/qq_35504602/article/details/108054416%22%E9%85%8D%E7%BD%AE%E8%BF%9E%E6%8E%A5%22">VS studio</a></li>
</ul>
<h3 id="起源与定义">起源与定义</h3>
<ul>
<li>起源：由约翰·格鲁伯（John Gruber）创建，旨在简化纯文本格式的文档编写。</li>
<li>定义：一种纯文本格式的标记语言，可选择性地转换为有效的XHTML（或HTML）。</li>
<li>特性：语法简单，纯文本，可使用文本编辑器打开，并化成其他格式（HTML文档等）。</li>
</ul>
<h3 id="常用语法">常用语法</h3>
<ul>
<li>标题: #+“空格”+标题内容，得到标题，多个#号得到多级标题，最多6级；</li>
<li>引用：&gt;+“空格”+内容，得到引用内容</li>
<li>有序列表：序号+“空格”+内容<br>
 1 序列一<br>
 2 序列二<br>
 3 序列三</li>
<li>无序列表：-+“空格”+内容
<ul>
<li>a</li>
<li>b</li>
<li>c</li>
</ul>
</li>
<li>任务列表：-+‘‘空格’’+[ ],[]里面也要有空格
<ul>
<li>[ ] 任务一</li>
<li>[ ] 任务二</li>
<li>[ ] 任务三</li>
</ul>
</li>
<li>代码块：```c 三个反引号（键盘上和波浪线在一起）+语言  <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">在这里插入代码 </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>数学公式：$$,中间加公式（不会也不打算学，就不做实列了</li>
<li>表格：|A|B|C|	表格头<br>
   |:—|—: | :—: |对齐方式：左。右。居中。<br>
   |qq|eee|wwww |打完按enter</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">A</th>
<th style="text-align:right">B</th>
<th style="text-align:center">C</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">qqq</td>
<td style="text-align:right">eee</td>
<td style="text-align:center">www</td>
</tr>
</tbody>
</table>
<ul>
<li>脚注：ABC [ ^abc]————在文末或者下一行+[ ^abc]:注释内容就行<br>
ABC[^abc]<br>
[^abc]:skfkdsaif</li>
<li>横线：— 三个-生成一条横线，打完按enter</li>
</ul>
<hr>
<ul>
<li>链接：[ 百度]( caidu m&quot;注释&quot;) 会得到一个链接,中间的网址正确的话<br>
 <a href="baidu.com%22%E6%B3%A8%E9%87%8A%22"> 百度</a></li>
<li>图片：![百度]（）括号里面是图片链接</li>
<li>视频：直接找到网站上的视频，复制嵌入链接粘贴即可</li>
</ul>
<h3 id="行内格式">行内格式</h3>
<ul>
<li>斜体：**</li>
<li>加粗：****</li>
<li>编写行内代码：''反引号</li>
</ul>
<p><code>ssss</code></p>
<ul>
<li>下划线：&lt; u&gt;&lt; /u&gt;</li>
<li>行内数学公式：$$</li>
<li>高亮文字：== a==</li>
<li>首行缩进：&amp;emsp；</li>
</ul>
]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo+butterfly+Github</title>
    <url>/2024/06/23/hexo-butterfly-Github/</url>
    <content><![CDATA[<h3 id="配置butterfly时总结出来的的经验">配置butterfly时总结出来的的经验</h3>
<ol>
<li>一步一步配，每配一次，<code>hexo s</code>一次，出问题了就查</li>
<li>出现报错的情况下，可以先试着<code>hexo clean&amp;hexo g&amp;hexo s</code>多来几次</li>
</ol>
<h3 id="我的文件结构注意事项">我的文件结构注意事项</h3>
<ol>
<li>在hexo根目录下的_config.yml和_config.butterfly.yml</li>
<li>没有特别提到的话，数据相关文件应该都是在/source/里面</li>
<li>文章的创建用<code>hexo new &quot;name&quot;</code>,页面的创建用的<code>hexo new page </code></li>
</ol>
<h3 id="用代码说话，两个配置文件最容易出问题">用代码说话，两个配置文件最容易出问题</h3>
<h4 id="config-butterfly-yml">_config.butterfly.yml</h4>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果你用vs编程发现最后主页中文是乱码，</span></span><br><span class="line"><span class="comment">#是因为vs默认生成的文件不按照utf-8，请按照这个解决 https://blog.csdn.net/qq_41868108/article/details/105750175</span></span><br><span class="line"><span class="comment">#浏览器图标修改</span></span><br><span class="line"><span class="attr">favicon:</span> <span class="string">/image/luogic.jpg</span></span><br><span class="line"><span class="comment">#导航栏设置 最上面的一栏，logo是最左边的小圈圈</span></span><br><span class="line"><span class="attr">nav:</span></span><br><span class="line">  <span class="attr">logo:</span> <span class="string">/image/微信图片_202406231044301.jpg</span></span><br><span class="line">  <span class="attr">display_title:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">fixed:</span> <span class="literal">false</span> <span class="comment"># fixed navigation bar    </span></span><br><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#这里是右上角的设置 格式是，/文件夹路劲/|| fas图标</span></span><br><span class="line"><span class="comment">#（一定要建立文件夹，不如找不到会报错） </span></span><br><span class="line"><span class="comment">#这里的fas图标 它用的是一个公司发行的标准图标图</span></span><br><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">首页:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="string">分类:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-folder-open</span></span><br><span class="line">  <span class="string">时间轴:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-archive</span></span><br><span class="line">  <span class="string">标签:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="string">其他||fa</span> <span class="attr">fa-heartbeat:</span></span><br><span class="line">    <span class="string">音乐:</span> <span class="string">/music/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-music</span></span><br><span class="line">    <span class="string">照片:</span> <span class="string">/Gallery/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-images</span></span><br><span class="line">    <span class="string">电影:</span> <span class="string">/movies/</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-video</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#网站副标题，中间标题下面一点点</span></span><br><span class="line"><span class="comment"># 主页subtitle</span></span><br><span class="line"><span class="attr">subtitle:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Typewriter Effect (打字效果)</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">startDelay:</span> <span class="number">300</span> <span class="comment"># time before typing starts in milliseconds</span></span><br><span class="line">  <span class="attr">typeSpeed:</span> <span class="number">200</span> <span class="comment"># type speed in milliseconds</span></span><br><span class="line">  <span class="attr">backSpeed:</span> <span class="number">800</span> <span class="comment"># backspacing speed in milliseconds</span></span><br><span class="line">  <span class="comment"># loop (循环打字)</span></span><br><span class="line">  <span class="attr">loop:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># source 调用三方服务</span></span><br><span class="line">  <span class="comment"># source: false 开关调用</span></span><br><span class="line">  <span class="comment"># subtitle 会先显示 source , 再显示 sub 的內容</span></span><br><span class="line">  <span class="attr">source:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># 如果关闭打字效果，subtitle 只会显示 sub 的第一行文字</span></span><br><span class="line">  <span class="attr">sub:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">飒飒西风满院栽，蕊寒香冷蝶难来</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">他年我若为青帝，报与桃花一处开</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#页面 右侧个人信息相关的设置</span></span><br><span class="line"><span class="comment">#头像 如果报错或者显示的是吃豆小人，检查你的名称，一定要正确</span></span><br><span class="line"><span class="attr">avatar:</span></span><br><span class="line">  <span class="attr">img:</span> <span class="string">/image/luogic.jpg</span></span><br><span class="line">  <span class="comment">#effect: true # 头像会一直转，转的贼快，太鬼畜了（emmm，超级抽象，别设置</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#顶部图片设置，就是主页的那张背景图，建议设置400px，默认的全屏容易让人找不到博客在哪里</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">index_img:</span> <span class="string">/image/流萤.jpg</span></span><br><span class="line"><span class="attr">default_top_img:</span> <span class="string">/image/流萤.jpg</span></span><br><span class="line"><span class="attr">index_top_img_height:</span>  <span class="comment">#顶部图高度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#背景动态</span></span><br><span class="line"><span class="attr">canvas_fluttering_ribbon:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">false</span> <span class="comment"># false 手机端不显示 true 手机端显示</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#页面加载动画</span></span><br><span class="line"><span class="comment">#加载动画</span></span><br><span class="line"><span class="attr">preloader:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">source:</span> <span class="number">1</span> <span class="comment">#可选值1=fullpage或2=progress bar，可查看https://codebyzach.github.io/pace/</span></span><br><span class="line">  <span class="attr">pace_css_url:</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#池塘养鱼（最底部）+渐变色</span></span><br><span class="line"><span class="attr">inject:</span></span><br><span class="line"> <span class="attr">head:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&lt;script</span> <span class="string">src=&quot;/styles/fish.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&lt;script</span> <span class="string">src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/styles/main.css&quot;&gt;</span>   </span><br><span class="line"> <span class="attr">bottom:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">&lt;script</span> <span class="string">src=&quot;https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">&lt;script</span> <span class="string">src=&quot;https://cdn.jsdelivr.net/gh/xiabo2/CDN@latest/fishes.js&quot;&gt;&lt;/script&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#搜索功能</span></span><br><span class="line"><span class="comment"># Local search</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Preload the search data when the page loads.</span></span><br><span class="line">  <span class="attr">preload:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Show top n results per article, show all results by setting to -1</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment"># Unescape html strings to the readable one.</span></span><br><span class="line">  <span class="attr">unescape:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">CDN:</span></span><br><span class="line"><span class="comment">#数学公式支持</span></span><br><span class="line"><span class="attr">katex:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># true 表示每一页都加载katex.js</span></span><br><span class="line">  <span class="comment"># false 需要时加载，须在使用的Markdown Front-matter 加上 katex: true</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">hide_scrollbar:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h4 id="config-yml">_config.yml</h4>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Hexo Configuration</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/configuration.html</span></span><br><span class="line"><span class="comment">## Source: https://github.com/hexojs/hexo/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Site</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">龙锦</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;买不起茅台 &#x27;</span></span><br><span class="line"><span class="attr">keywords:</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">龙金伟</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://username.github.io</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">:year/:month/:day/:title/</span></span><br><span class="line"><span class="attr">permalink_defaults:</span></span><br><span class="line"><span class="attr">pretty_urls:</span></span><br><span class="line">  <span class="attr">trailing_index:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span></span><br><span class="line">  <span class="attr">trailing_html:</span> <span class="literal">true</span> <span class="comment"># Set to false to remove trailing &#x27;.html&#x27; from permalinks</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory</span></span><br><span class="line"><span class="attr">source_dir:</span> <span class="string">source</span></span><br><span class="line"><span class="attr">public_dir:</span> <span class="string">public</span></span><br><span class="line"><span class="attr">tag_dir:</span> <span class="string">tags</span></span><br><span class="line"><span class="attr">archive_dir:</span> <span class="string">archives</span></span><br><span class="line"><span class="attr">category_dir:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">code_dir:</span> <span class="string">downloads/code</span></span><br><span class="line"><span class="attr">i18n_dir:</span> <span class="string">:lang</span></span><br><span class="line"><span class="attr">skip_render:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Writing</span></span><br><span class="line"><span class="attr">new_post_name:</span> <span class="string">:title.md</span> <span class="comment"># File name of new posts</span></span><br><span class="line"><span class="attr">default_layout:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">titlecase:</span> <span class="literal">false</span> <span class="comment"># Transform title into titlecase</span></span><br><span class="line"><span class="attr">external_link:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># Open external links in new tab</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">site</span> <span class="comment"># Apply to the whole site</span></span><br><span class="line">  <span class="attr">exclude:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="attr">filename_case:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">render_drafts:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">relative_link:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">future:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">syntax_highlighter:</span> <span class="string">highlight.js</span></span><br><span class="line"><span class="attr">highlight:</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">auto_detect:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hljs:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">prismjs:</span></span><br><span class="line">  <span class="attr">preprocess:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Home page setting</span></span><br><span class="line"><span class="comment"># path: Root path for your blogs index page. (default = &#x27;&#x27;)</span></span><br><span class="line"><span class="comment"># per_page: Posts displayed per page. (0 = disable pagination)</span></span><br><span class="line"><span class="comment"># order_by: Posts order. (Order by date descending by default)</span></span><br><span class="line"><span class="attr">index_generator:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">order_by:</span> <span class="string">-date</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Category &amp; Tag</span></span><br><span class="line"><span class="attr">default_category:</span> <span class="string">uncategorized</span></span><br><span class="line"><span class="attr">category_map:</span></span><br><span class="line"><span class="attr">tag_map:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Metadata elements</span></span><br><span class="line"><span class="comment">## https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta</span></span><br><span class="line"><span class="attr">meta_generator:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Date / Time format</span></span><br><span class="line"><span class="comment">## Hexo uses Moment.js to parse and display date</span></span><br><span class="line"><span class="comment">## You can customize the date format as defined in</span></span><br><span class="line"><span class="comment">## http://momentjs.com/docs/#/displaying/format/</span></span><br><span class="line"><span class="attr">date_format:</span> <span class="string">YYYY-MM-DD</span></span><br><span class="line"><span class="attr">time_format:</span> <span class="string">HH:mm:ss</span></span><br><span class="line"><span class="comment">## updated_option supports &#x27;mtime&#x27;, &#x27;date&#x27;, &#x27;empty&#x27;</span></span><br><span class="line"><span class="attr">updated_option:</span> <span class="string">&#x27;mtime&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pagination</span></span><br><span class="line"><span class="comment">## Set per_page to 0 to disable pagination</span></span><br><span class="line"><span class="attr">per_page:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">pagination_dir:</span> <span class="string">page</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Include / Exclude file(s)</span></span><br><span class="line"><span class="comment">## include:/exclude: options only apply to the &#x27;source/&#x27; folder</span></span><br><span class="line"><span class="attr">include:</span></span><br><span class="line"><span class="attr">exclude:</span></span><br><span class="line"><span class="attr">ignore:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extensions</span></span><br><span class="line"><span class="comment">## Plugins: https://hexo.io/plugins/</span></span><br><span class="line"><span class="comment">## Themes: https://hexo.io/themes/</span></span><br><span class="line"><span class="attr">theme:</span> <span class="string">butterfly</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/one-command-deployment</span></span><br><span class="line"><span class="comment"># deploy:</span></span><br><span class="line"><span class="comment">#   type: &#x27;&#x27;</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/longjinw/longjinw.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br><span class="line">  <span class="comment"># message: Site updated: &#123;&#123; now(&#x27;YYYY-MM-DD HH:mm:ss&#x27;) &#125;&#125;)</span></span><br><span class="line"><span class="comment">#搜索</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">content:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br><span class="line"><span class="comment">#数学支chi</span></span><br><span class="line"><span class="attr">markdown:</span></span><br><span class="line">    <span class="attr">plugins:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;@renbaoshuo/markdown-it-katex&#x27;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
